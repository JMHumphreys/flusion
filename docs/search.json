[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Welcome\nf(l)usion is a data set that provides estimates for hospitalizations that resulted from influenza. Weekly estimates are provided for 56 U.S. States and Territories from October 2010 through May 2023.\nThe f(l)usion data and the methods used to produce it are experimental and should not be considered as authoritative.\nThe menu at left provides links to explore f(l)usion and to overview the methods used to produce the data.\n\nDownload f(l)usion Data\n Download Data  f(l)usion v.1 (2.4 mb, csv)"
  },
  {
    "objectID": "construction/organize/organize.html",
    "href": "construction/organize/organize.html",
    "title": "Data Organization",
    "section": "",
    "text": "Organizing data for a three-part joint model can be complex. This script walks through DataStack construction where a DataStack is a list object that holds all data for model fitting. Because this is a three-part model, DataStacks will be created for each submodel (e.g., an ILI submodel, a NREVSS submodel, and a HHS submodel) then the three submodel DataStacks will be combined as a joint_stack. As part of DataStack construction, a three-part response/dependent variable will be specified as a three-column matrix.\nNote: This script requires that data Preprocessing has already been completed and all Preprocessing objects are available in the working environment.\n\n\n\n\n\nThe ILI model will occupy the base level of the joint model and pass information to both the middle level submodel (NREVSS) and the top level HHS submodel.\n\n\nHide code\nilinet_full <- as.data.frame(ilinet_full) %>%\n  mutate(y_ili = unweighted.s, #Response variable, logit transformed percentage of influenza-like illnesses.\n         l.pop.ili = log(population), #log population size\n         Region.1.ili = Region, #an identifier for each location (i.e., States and Territories)\n         Region.2.ili = Region,\n         Region.3.ili = Region,\n         Region.4.ili = Region,\n         ts_week.1.ili = ts_week, #integer time step for epiweeks 2010 to 2023-epiweek-22\n         ts_week.2.ili = ts_week,\n         ts_week.3.ili = ts_week,\n         ts_week.4.ili = ts_week,\n         state.ili = abbreviation, #State abbreviations\n         year.ili = as.integer(as.factor(year)), #integer time step for years\n         year.ili.1 = as.integer(as.factor(year)),\n         year.ili.2 = as.integer(as.factor(year)),\n         year.ili.3 = as.integer(as.factor(year)),\n         source = 1) #just an ID to identify ILI data\n\n\n\nili.lst = list(list(intercept1 = rep(1, dim(ilinet_full)[1])), #custom intercept\n          list(l.pop.ili = ilinet_full[,\"l.pop.ili\"],  #log-population              \n               year.ili = ilinet_full[,\"year.ili\"],\n               en_est.s = ilinet_full[,\"en_est.s\"], #amplitude of temporal trend in FluSurv cases\n               year.ili.1 = ilinet_full[,\"year.ili.1\"],\n               year.ili.2 = ilinet_full[,\"year.ili.2\"],\n               year.ili.3 = ilinet_full[,\"year.ili.3\"],\n               ts_week = ilinet_full[,\"ts_week.1.ili\"],\n               ts_week.fs = ilinet_full[,\"ts_week.1.ili\"],\n               ts_week.iid = ilinet_full[,\"ts_week.1.ili\"],\n               ts_week.1.ili = ilinet_full[,\"ts_week.1.ili\"],\n               ts_week.2.ili = ilinet_full[,\"ts_week.2.ili\"],\n               ts_week.3.ili = ilinet_full[,\"ts_week.3.ili\"],\n               Region = ilinet_full[,\"Region.1.ili\"],\n               Region.1 = ilinet_full[,\"Region.1.ili\"],\n               Region.2 = ilinet_full[,\"Region.1.ili\"],\n               Region.cross = ilinet_full[,\"Region.1.ili\"],\n               Region.1.ili = ilinet_full[,\"Region.1.ili\"],\n               Region.2.ili = ilinet_full[,\"Region.2.ili\"],\n               Region.3.ili = ilinet_full[,\"Region.3.ili\"],\n               Region.4.ili = ilinet_full[,\"Region.4.ili\"],\n               st_int.ili = ilinet_full[,\"st_int\"], #State-Time interactions\n               state.ili = ilinet_full[,\"state.ili\"],\n               dsource = ilinet_full[,\"source\"]))\n\n# The ILI DataStack\nili.stk = inla.stack(data = list(Y = cbind(ilinet_full$y_ili, NA, NA)), #base level response in 1st slot, NAs are placeholders for other two\n                                      A = list(1,1),  #optional matrix object, not used in this analysis     \n                                effects = ili.lst,    # list object created above with indices and variables   \n                                    tag = \"ili\")      #arbitrary name/label to pull data later\n\n\n\n\n\nSimilar to ILI DataStack above, creating one for the NREVSS submodel. Note that some variable names are the same as in the ILI DataStack (e.g., Region and st_int) BUT some are specific to this DataStack with a .nv designation: If a variable name is included in the joint model formula, it can only contribute to the submodels that also have it. This provides control such that some variables may be specific to one submodel or one DataStack, whereas other variables may be applicable to all submodels concurrently.\n\n\nHide code\nnrevss_full <- as.data.frame(nrevss_full) %>%\n  mutate(y_nrvs = Apos.s, #confirmed positive influenza A, logit transformed percentage\n         l.pop.nv = log(population),\n         Region.1.nv = Region,\n         Region.2.nv = Region,\n         Region.3.nv = Region,\n         Region.4.nv = Region,\n         ts_week.1.nv = ts_week,\n         ts_week.2.nv = ts_week,\n         ts_week.3.nv = ts_week,\n         ts_week.4.nv = ts_week,\n         state.nv = abbreviation,\n         year.nv = as.integer(as.factor(year)),\n         year.nv.1 = as.integer(as.factor(year)),\n         year.nv.2 = as.integer(as.factor(year)),\n         year.nv.3 = as.integer(as.factor(year)),\n         source = 2)\n\nnv.lst = list(list(intercept2 = rep(1, dim(nrevss_full)[1])), # custom intercept\n          list(l.pop.nv = nrevss_full[,\"l.pop.nv\"], \n               en_est.s = nrevss_full[,\"en_est.s\"],\n               year.nv = nrevss_full[,\"year.nv\"],\n               year.nv.1 = nrevss_full[,\"year.nv.1\"],\n               year.nv.2 = nrevss_full[,\"year.nv.2\"],\n               year.nv.3 = nrevss_full[,\"year.nv.3\"],\n               ts_week = nrevss_full[,\"ts_week.1.nv\"],\n               ts_week.fs = nrevss_full[,\"ts_week.1.nv\"],\n               ts_week.iid = nrevss_full[,\"ts_week.1.nv\"],\n               ts_week.1.nv = nrevss_full[,\"ts_week.1.nv\"],\n               ts_week.2.nv = nrevss_full[,\"ts_week.2.nv\"],\n               ts_week.3.nv = nrevss_full[,\"ts_week.3.nv\"],\n               Region = nrevss_full[,\"Region.1.nv\"],\n               Region.1 = nrevss_full[,\"Region.1.nv\"],\n               Region.2 = nrevss_full[,\"Region.1.nv\"],\n               Region.cross = nrevss_full[,\"Region.1.nv\"],\n               Region.1.nv = nrevss_full[,\"Region.1.nv\"],\n               Region.2.nv = nrevss_full[,\"Region.2.nv\"],\n               Region.3.nv = nrevss_full[,\"Region.3.nv\"],\n               Region.4.nv = nrevss_full[,\"Region.4.nv\"],\n               st_int = nrevss_full[,\"st_int\"],\n               st_int.nv = nrevss_full[,\"st_int\"],\n               state.nv = nrevss_full[,\"state.nv\"],\n               dsource = nrevss_full[,\"source\"]))\n\n\n#NREVSS DataStack\nnv.stk = inla.stack(data = list(Y = cbind(NA, nrevss_full$y_nrvs, NA)), #NA in the first and last columns (for ILI and HHS responses)\n                                      A = list(1,1),       \n                                effects = nv.lst,        \n                                    tag = \"nrvs\")\n\n\n\n\n\nMuch the same as the ILI and NREVVS DataStacks.\n\n\nHide code\nflu_HHS_full <- as.data.frame(flu_HHS_full) %>%\n  mutate(y_hhs = log(hosp_inc+0.0001), #log hospital incidence (response variable)\n         l.pop.hhs = log(population),\n         Region.1.hhs = Region,\n         Region.2.hhs = Region,\n         Region.3.hhs = Region,\n         Region.4.hhs = Region,\n         ts_week.1.hhs = ts_week,\n         ts_week.2.hhs = ts_week,\n         ts_week.3.hhs = ts_week,\n         ts_week.4.hhs = ts_week,\n         state.hhs = abbreviation,\n         year.hhs = as.integer(as.factor(year)),\n         year.hhs.1 = as.integer(as.factor(year)),\n         year.hhs.2 = as.integer(as.factor(year)),\n         year.hhs.3 = as.integer(as.factor(year)),\n         source = 3)\n\nhhs.lst = list(list(intercept3 = rep(1, dim(flu_HHS_full)[1])), \n          list(l.pop.hhs = flu_HHS_full[,\"l.pop.hhs\"], \n               en_est.s = flu_HHS_full[,\"en_est.s\"],\n               year.hhs = flu_HHS_full[,\"year.hhs\"],\n               year.hhs.1 = flu_HHS_full[,\"year.hhs\"],\n               year.hhs.2 = flu_HHS_full[,\"year.hhs\"],\n               year.hhs.3 = flu_HHS_full[,\"year.hhs\"],\n               ts_week.fs = flu_HHS_full[,\"ts_week.1.hhs\"],\n               ts_week.c = flu_HHS_full[,\"ts_week.1.hhs\"],\n               ts_week.iid.c = flu_HHS_full[,\"ts_week.1.hhs\"],\n               ts_week.1.hhs = flu_HHS_full[,\"ts_week.1.hhs\"],\n               ts_week.2.hhs = flu_HHS_full[,\"ts_week.2.hhs\"],\n               ts_week.3.hhs = flu_HHS_full[,\"ts_week.3.hhs\"],\n               Region = flu_HHS_full[,\"Region.1.hhs\"],\n               Region.c = flu_HHS_full[,\"Region.1.hhs\"],\n               Region.1.c = flu_HHS_full[,\"Region.1.hhs\"],\n               Region.2.c = flu_HHS_full[,\"Region.1.hhs\"],\n               Region.1.hhs = flu_HHS_full[,\"Region.1.hhs\"],\n               Region.2.hhs = flu_HHS_full[,\"Region.2.hhs\"],\n               Region.3.hhs = flu_HHS_full[,\"Region.3.hhs\"],\n               Region.4.hhs = flu_HHS_full[,\"Region.4.hhs\"],\n               state.hhs = flu_HHS_full[,\"state.hhs\"],\n               st_int.c = flu_HHS_full[,\"st_int\"],\n               dsource = flu_HHS_full[,\"source\"]))\n\n# HHS DataStack  \nhhs.stk = inla.stack(data = list(Y = cbind(NA, NA, flu_HHS_full$y_hhs)), #NAs for ILI and NREVESS responses, HHS in 3rd spot\n                                      A = list(1,1),       \n                                effects = hhs.lst,        \n                                    tag = \"hhs\")   \n\n\n\n\n\nJoining all three above DataStacks to a common object, joint DataStack. This is all the data needed for running the model.\n\n\nHide code\njoint_stack <- inla.stack(ili.stk, nv.stk, hhs.stk)"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html",
    "href": "construction/preprocessing/preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "Setup working environment and loading necessary packages.\n\n\n\n\nHide code\n#wrangling\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(data.table, include.only = \"fread\")\nlibrary(cdcfluview)\nlibrary(yaml)\n\n#spatial\nlibrary(sp)\nlibrary(sf)\nlibrary(spdep)\nlibrary(rgeos)\nlibrary(igraph)\nlibrary(maptools)\nlibrary(mapproj)\nlibrary(CovidCAR)\n#devtools::install_github(\"JMHumphreys/CovidCAR\")\n\n#messages\nlibrary(cli)\n\n#inference\nlibrary(INLA)\n\n#Utilities\n#source(\"./R/utilities.R\")\n\noptions(dplyr.summarise.inform = FALSE)\n\n#function\ndownload_file <- function(url, filename) {\n  download.file(url, destfile = filename, method = \"auto\", quiet = FALSE, mode = \"wb\")\n}"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#flusurv",
    "href": "construction/preprocessing/preprocessing.html#flusurv",
    "title": "Preprocessing",
    "section": "FluSurv",
    "text": "FluSurv\nBuild a flu hospitalization data file from individual state reports and all available years. The hospitalizations() function from the cdcfluview package does most of the work by querying FluView, but seems only to be able to take small bites at a time.\n\n\nHide code\nmyRegions <- surveillance_areas() \n\nflusurv_all <- do.call(rbind, lapply(seq_len(dim(myRegions)[1]), function(i) {\n  hospitalizations(surveillance_area = myRegions$surveillance_area[i], region = myRegions$region[i])\n}))\n\n\nWrangle Flusurv data:\nNote that the cdcfluview package only includes through Spring of 2020. Because of this, the data is filtered at 2019 and a static file manually downloaded from FluView with more recnt reports (eventually this data will be moved to www.healthdata.gov).\n\n\nHide code\nrange(flusurv_all$year)\n\n\n[1] 2003 2020\n\n\nHide code\nflusurv <- flusurv_all %>%\n  filter(age_label == \"Overall\",\n         region != \"Entire Network\",\n         year >= 2010 & year <= 2019) %>% #the pkg fails on dates after 2020,ugh\n  mutate(location_name = region,\n         network = surveillance_area,\n         weeklyrate = as.numeric(weeklyrate),\n         epiweek = year_wk_num) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n  \n#manual download from site 2023-06-01\nflusurv_2020 <- fread(\"D:/Github/flusion/data/FluSurveillance_2020.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  filter(AGECATEGORY == \"Overall\",\n         SEXCATEGORY == \"Overall\",\n         RACECATEGORY == \"Overall\",\n         CATCHMENT != \"Entire Network\",\n         MMWRYEAR >= 2020) %>% #Prior to this date was downloaded in code above\n  mutate(location_name = CATCHMENT,\n         network = NETWORK,\n         year = MMWRYEAR,\n         epiweek = MMWRWEEK,\n         rate = CUMULATIVERATE,\n         weeklyrate = as.numeric(WEEKLYRATE)) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n\n#Join date ranges and scale weeklyrate\nflusurv = rbind(flusurv, flusurv_2020)\nflusurv$weeklyrate.s = as.numeric(scale(flusurv$weeklyrate, scale = T, center=T))\n\n#combine NY data\nflusurv$location_name[flusurv$location_name == \"New York - Albany\"] = \"New York\"\nflusurv$location_name[flusurv$location_name == \"New York - Rochester\"] =\"New York\"\n\nflusurv <- flusurv %>%\n  group_by(location_name, year, epiweek) %>%\n  summarise(rate = mean(rate, na.rm=T),\n            weeklyrate = mean(weeklyrate, na.rm=T),\n            weeklyrate.s = mean(weeklyrate.s, na.rm=T))\n\n\n#Check for duplicates\nunique(duplicated(flusurv))\n\n\n[1] FALSE\n\n\nHide code\ndim(flusurv)\n\n\n[1] 5676    6\n\n\nHide code\nhead(flusurv)\n\n\n\n\n\n\nlocation_name\nyear\nepiweek\nrate\nweeklyrate\nweeklyrate.s\n\n\n\n\nCalifornia\n2010\n1\nNA\n0.4\n-0.4771582\n\n\nCalifornia\n2010\n2\nNA\n0.2\n-0.5561987\n\n\nCalifornia\n2010\n3\nNA\n0.2\n-0.5561987\n\n\nCalifornia\n2010\n4\nNA\n0.2\n-0.5561987\n\n\nCalifornia\n2010\n5\nNA\n0.2\n-0.5561987\n\n\nCalifornia\n2010\n6\nNA\n0.1\n-0.5957189\n\n\n\n\n\n\nSame FluSurv process as above, but now for the Full Network reports\n\n\nHide code\nflusurv_en <- flusurv_all %>%\n  filter(age_label == \"Overall\",\n         region == \"Entire Network\",\n         year >= 2010 & year <= 2019) %>% #the pkg fails on dates after 2020,ugh\n  mutate(location_name = region,\n         network = surveillance_area,\n         epiweek = year_wk_num) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n\nflusurv_en2020 <- fread(\"D:/Github/flusion/data/FluSurveillance_2020.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  filter(AGECATEGORY == \"Overall\",\n         SEXCATEGORY == \"Overall\",\n         RACECATEGORY == \"Overall\",\n         CATCHMENT == \"Entire Network\",\n         MMWRYEAR >= 2020) %>% #the pkg fails on dates after 2020,ugh\n  mutate(location_name = CATCHMENT,\n         network = NETWORK,\n         year = MMWRYEAR,\n         epiweek = MMWRWEEK,\n         rate = CUMULATIVERATE,\n         weeklyrate = WEEKLYRATE) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n\n#Join\nflusurv_en <- rbind(flusurv_en, flusurv_en2020)\nunique(duplicated(flusurv_en))\n\n\n[1] FALSE\n\n\nHide code\ndim(flusurv_en)\n\n\n[1] 1131    6\n\n\nHide code\nhead(flusurv_en)\n\n\n\n\n\n\nlocation_name\nyear\nepiweek\nnetwork\nrate\nweeklyrate\n\n\n\n\nEntire Network\n2016\n40\nFluSurv-NET\n0.1\n0.1\n\n\nEntire Network\n2016\n41\nFluSurv-NET\n0.2\n0.1\n\n\nEntire Network\n2016\n42\nFluSurv-NET\n0.3\n0.1\n\n\nEntire Network\n2016\n43\nFluSurv-NET\n0.4\n0.1\n\n\nEntire Network\n2016\n44\nFluSurv-NET\n0.6\n0.1\n\n\nEntire Network\n2016\n45\nFluSurv-NET\n0.8\n0.2"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#ilinet-surveillance-data",
    "href": "construction/preprocessing/preprocessing.html#ilinet-surveillance-data",
    "title": "Preprocessing",
    "section": "ILINet Surveillance Data",
    "text": "ILINet Surveillance Data\nInfluenza Like Illness (ILI) data using cdcfluview package. Unlike FluSurv, data is available 2010-2013.\n\n\nHide code\nilinet <- ilinet(region = \"state\") %>%\n  mutate(location_name = region,\n         epiweek = week,\n         unweighted = as.numeric(unweighted_ili),\n         unweighted.s = unweighted,\n         total = ilitotal,\n         providers = num_of_providers) %>%\n  select(location_name, year, epiweek, unweighted, unweighted.s, total, providers)\n\n# Clip to between 0.0001 and 99.999\nilinet$unweighted.s <- pmin(pmax(as.numeric(ilinet$unweighted.s), 0.01), 99.99)/100\n\n# logit transform \nilinet$unweighted.s <- log(ilinet$unweighted.s/(1-ilinet$unweighted.s))\nrange(ilinet$unweighted.s, na.rm=T)\n\n\n[1] -9.210240 -1.423094\n\n\nHide code\nunique(duplicated(ilinet))\n\n\n[1] FALSE\n\n\nHide code\ndim(ilinet)\n\n\n[1] 35678     7\n\n\nHide code\nrange(ilinet$year)\n\n\n[1] 2010 2023\n\n\nHide code\nhead(ilinet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation_name\nyear\nepiweek\nunweighted\nunweighted.s\ntotal\nproviders\n\n\n\n\nAlabama\n2010\n40\n2.134770\n-3.825232\n249\n35\n\n\nAlaska\n2010\n40\n0.875146\n-4.729745\n15\n7\n\n\nArizona\n2010\n40\n0.674721\n-4.991856\n172\n49\n\n\nArkansas\n2010\n40\n0.696056\n-4.960510\n18\n15\n\n\nCalifornia\n2010\n40\n1.954120\n-3.915496\n632\n112\n\n\nColorado\n2010\n40\n0.660684\n-5.013021\n134\n14"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#covid19-rpihc-by-state-timeseries-raw",
    "href": "construction/preprocessing/preprocessing.html#covid19-rpihc-by-state-timeseries-raw",
    "title": "Preprocessing",
    "section": "COVID19 RPIHC by State Timeseries (raw)",
    "text": "COVID19 RPIHC by State Timeseries (raw)\nDownloading the COVID-19 Reported Patient Impact and Hospital Capacity by State Timeseries from https://healthdata.gov/.\n\n\nHide code\nurl <- \"https://healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD\"\nfilename <- \"D:/Github/flusion_model/data/flu_HHS.csv\"\n\ndownload_file(url, filename)\n\n\nRead and wrangle RPIHC:\n\n\nHide code\nflu_HHS <- fread(\"D:/Github/flusion_model/data/flu_HHS.csv\") %>%\n  mutate(abbreviation = state,\n         date = as_date(date) - 1, #1-day prior, per fluSight truth\n         year = year(date),\n         epiweek = epiweek(date)) %>%\n  group_by(abbreviation, year, epiweek) %>%\n  summarise(hosp_inc = sum(previous_day_admission_influenza_confirmed))\n\nunique(duplicated(flu_HHS))\n\n\n[1] FALSE\n\n\nHide code\ndim(flu_HHS)\n\n\n[1] 9293    4\n\n\nHide code\nrange(flu_HHS$year)\n\n\n[1] 2019 2023\n\n\nHide code\nhead(flu_HHS)\n\n\n\n\n\n\nabbreviation\nyear\nepiweek\nhosp_inc\n\n\n\n\nAK\n2020\n13\nNA\n\n\nAK\n2020\n14\nNA\n\n\nAK\n2020\n15\nNA\n\n\nAK\n2020\n16\nNA\n\n\nAK\n2020\n17\nNA\n\n\nAK\n2020\n18\nNA"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#nrevss",
    "href": "construction/preprocessing/preprocessing.html#nrevss",
    "title": "Preprocessing",
    "section": "NREVSS",
    "text": "NREVSS\nNational Respiratory and Enteric Virus Surveillance System.\nAgain, unfortunately only available through a manual: https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html\nFiles illustrated here were downloaded on June 2, 2023.\n\n\nHide code\nnrevss.1 <- fread(\"D:/Github/flusion/data/WHO_NREVSS_Combined_prior_to_2015_16.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  mutate(location_name = REGION,\n         year = YEAR,\n         epiweek = WEEK,\n         tot_perc = as.numeric(PERCENTPOSITIVE),\n         Bpos = as.numeric(B),\n         tot_samp = as.numeric(TOTALSPECIMENS),\n         Apos = tot_perc - ((Bpos/tot_samp)*100)) %>%\n  select(location_name, year, epiweek, Apos)\n\n\nnrevss.2 <- fread(\"D:/Github/flusion/data/WHO_NREVSS_Clinical_Labs.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  mutate(location_name = REGION,\n         year = YEAR,\n         epiweek = WEEK,\n         Apos = PERCENTA) %>%\n  select(location_name, year, epiweek, Apos) #Apos = Influenza A positive\n\n# Combine \nnrevss <- rbind(nrevss.1, nrevss.2)\n\n# Replace \"X\" \nnrevss$Apos[nrevss$Apos == \"X\"] <- NA\n\n# Clip to between 0.0001 and 99.999\nnrevss$Apos <- pmin(pmax(as.numeric(nrevss$Apos), 0.01), 99.99)/100\n\n# logit transform \nnrevss$Apos.s <- log(nrevss$Apos/(1-nrevss$Apos))\nunique(duplicated(nrevss))\n\n\n[1] FALSE\n\n\nHide code\nhead(nrevss)\n\n\n\n\n\n\nlocation_name\nyear\nepiweek\nApos\nApos.s\n\n\n\n\nAlabama\n2010\n40\n0.0001000\n-9.210240\n\n\nAlaska\n2010\n40\n0.0001000\n-9.210240\n\n\nArizona\n2010\n40\n0.0250000\n-3.663562\n\n\nArkansas\n2010\n40\n0.0001000\n-9.210240\n\n\nCalifornia\n2010\n40\n0.0273355\n-3.571852\n\n\nColorado\n2010\n40\n0.0079000\n-4.832961"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#location-table",
    "href": "construction/preprocessing/preprocessing.html#location-table",
    "title": "Preprocessing",
    "section": "Location Table",
    "text": "Location Table\nLocation codes and population numbers from FluSight. Should really get varying census over time period, but these are a start.\n\n\nHide code\nurl <- \"https://github.com/cdcepi/Flusight-forecast-data/raw/master/data-locations/locations.csv\"\nfilename <- \"D:/Github/flusion/data/locations.csv\"\n\ndownload_file(url, filename)\n\n\nRead locations:\n\n\nHide code\nlocations <- fread(\"D:/Github/flusion/data/locations.csv\") %>%\n  select(-c(count_rate1per100k, count_rate2per100k)) %>%\n  filter(location_name != \"US\") #remove aggregate group\n\nhead(locations)\n\n\n\n\n\n\nabbreviation\nlocation\nlocation_name\npopulation\n\n\n\n\nAL\n01\nAlabama\n5039877\n\n\nAK\n02\nAlaska\n732673\n\n\nAZ\n04\nArizona\n7276316\n\n\nAR\n05\nArkansas\n3025891\n\n\nCA\n06\nCalifornia\n39237836\n\n\nCO\n08\nColorado\n5812069"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#dates-and-locations",
    "href": "construction/preprocessing/preprocessing.html#dates-and-locations",
    "title": "Preprocessing",
    "section": "Dates and Locations",
    "text": "Dates and Locations\n\n\nHide code\nmyYears <- seq(2010, 2023, by = 1)\nweek_nums <- 1:52\n\nyear_set <- lapply(myYears, function(year) {\n  tmp_frame <- locations %>% mutate(year = year)\n  \n  weekly_set <- lapply(week_nums, function(week_num) {\n    tmp_frame_wk <- tmp_frame %>% mutate(epiweek = week_num)\n    return(tmp_frame_wk)\n  })\n  \n  weekly_set <- do.call(rbind, weekly_set)\n  return(weekly_set)\n})\n\ntemplate <- do.call(rbind, year_set)\n\ndim(template)\n\n\n[1] 38584     6\n\n\nHide code\nhead(template) #all states and times represented\n\n\n\n\n\n\nabbreviation\nlocation\nlocation_name\npopulation\nyear\nepiweek\n\n\n\n\nAL\n01\nAlabama\n5039877\n2010\n1\n\n\nAK\n02\nAlaska\n732673\n2010\n1\n\n\nAZ\n04\nArizona\n7276316\n2010\n1\n\n\nAR\n05\nArkansas\n3025891\n2010\n1\n\n\nCA\n06\nCalifornia\n39237836\n2010\n1\n\n\nCO\n08\nColorado\n5812069\n2010\n1\n\n\n\n\n\n\nHide code\nfirst_record <- min(subset(nrevss, year == 2010)$epiweek) #drop before nrevss data was collected\ntemplate$drop_old <- ifelse(template$year == 2010 & template$epiweek < first_record, \"drop\", \"keep\")\n\n#most_recent <- max(subset(flu_HHS, year == 2023)$epiweek) #drop future dates\nmost_recent <- 22 #date available when model run\ntemplate$drop_new <- ifelse(template$year == 2023 & template$epiweek > most_recent, \"drop\", \"keep\")\n\ntemplate <- template %>% \n  filter(drop_old == \"keep\" &\n         drop_new == \"keep\") %>%\n  select(-c(drop_old, drop_new))\n\nunique(duplicated(template))\n\n\n[1] FALSE"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#reduce-for-testing",
    "href": "construction/preprocessing/preprocessing.html#reduce-for-testing",
    "title": "Preprocessing",
    "section": "Reduce for Testing",
    "text": "Reduce for Testing\nRunning the analysis from 2010 through 2023-Epiweek-22.\n\n\nHide code\ntemplate <- template %>% filter(year >= 2010)"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#time-steps",
    "href": "construction/preprocessing/preprocessing.html#time-steps",
    "title": "Preprocessing",
    "section": "Time Steps",
    "text": "Time Steps\nAn index with sequential timesteps.\n\n\nHide code\ntemplate <- template %>%\n  arrange(year, epiweek) %>%\n  mutate(ts_week = as.integer(as.factor(year + (epiweek/53))))\n\n\nrange(template$ts_week) #number of epiweeks\n\n\n[1]   1 659"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#get-geographic-boundaries",
    "href": "construction/preprocessing/preprocessing.html#get-geographic-boundaries",
    "title": "Preprocessing",
    "section": "Get Geographic Boundaries",
    "text": "Get Geographic Boundaries\n\n\nHide code\nStates <- download_boundaries(unit = \"state\")\n\n\nReading layer `us-state-boundaries' from data source \n  `D:\\Github\\flusion\\data\\2010-01-01-CovidCAR-run2023-06-12\\polygons' \n  using driver `ESRI Shapefile'\nSimple feature collection with 56 features and 20 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.44069\nGeodetic CRS:  WGS 84\n\n\nHide code\nclass(States)\n\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nHide code\nhead(States@data[,c(\"Region\", \"State\")]) #appended attributes  \n\n\n\n\n\n\nRegion\nState\n\n\n\n\n1\nVirgin Islands\n\n\n2\nWisconsin\n\n\n3\nVermont\n\n\n4\nNew Jersey\n\n\n5\nColorado\n\n\n6\nSouth Carolina"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#adjacency",
    "href": "construction/preprocessing/preprocessing.html#adjacency",
    "title": "Preprocessing",
    "section": "Adjacency",
    "text": "Adjacency\n\n\nHide code\nnb_flusion = get_neighbors(States, connect=TRUE)\nsummary(nb_flusion)\n\n\nNeighbour list object:\nNumber of regions: 56 \nNumber of nonzero links: 242 \nPercentage nonzero weights: 7.716837 \nAverage number of links: 4.321429 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8 \n 5  3 10 12 10 11  3  2 \n5 least connected regions:\n1 13 38 42 54 with 1 link\n2 most connected regions:\n49 56 with 8 links\n\n\nHide code\n#view\nplot_neighbors(States, nb_flusion)\n\n\n\n\n\nHide code\n#convert to matrix\nnb2INLA(\"J\", nb_flusion)\nJ = inla.read.graph(\"J\")"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#template-spatial-index",
    "href": "construction/preprocessing/preprocessing.html#template-spatial-index",
    "title": "Preprocessing",
    "section": "Template Spatial Index",
    "text": "Template Spatial Index\n\n\nHide code\ntemplate$Region =  with(States@data[,c(\"Region\", \"State\")],\n                       Region[match(\n                        template$location_name,\n                                 State)])"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#add-entire-network",
    "href": "construction/preprocessing/preprocessing.html#add-entire-network",
    "title": "Preprocessing",
    "section": "Add Entire Network",
    "text": "Add Entire Network\nGetting the flue weeklyrate from FluSurv. Not that this is only the time trend from FluSurv and is not loaction specific.\n\n\nHide code\nen_match <- flusurv_en %>%\n  group_by(year, epiweek) %>%\n  summarise(en_est = mean(as.numeric(weeklyrate), na.rm=TRUE)) %>%\n  select(year, epiweek, en_est)\n\n# Clip to between 0.0001 and 99.999\nen_match$en_est.s <- pmin(pmax(as.numeric(en_match$en_est), 0.01), 99.99)/100\n\n# logit transform \nen_match$en_est.s <- round(log(en_match$en_est.s/(1-en_match$en_est.s)), 3)\nrange(en_match$en_est.s, na.rm=T)\n\n\n[1] -9.21 -2.19\n\n\nHide code\ntemplate <- left_join(template, en_match, by = c(\"year\", \"epiweek\"))\nunique(duplicated(template))\n\n\n[1] FALSE"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#space-time-interaction-index",
    "href": "construction/preprocessing/preprocessing.html#space-time-interaction-index",
    "title": "Preprocessing",
    "section": "Space-Time Interaction Index",
    "text": "Space-Time Interaction Index\nAll location-time combinations.\n\n\nHide code\ntemplate$st_int <- as.integer(as.factor(paste0(template$Region, \".\", template$ts_week)))\nrange(template$st_int)\n\n\n[1]     1 34927"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#view-coverage",
    "href": "construction/preprocessing/preprocessing.html#view-coverage",
    "title": "Preprocessing",
    "section": "View Coverage",
    "text": "View Coverage\nLooking at holes in the data. Not interested in exact values, only comparing data coverage.\n\n\nHide code\nfs_plt <- flusurv_full %>% \n  mutate(value = weeklyrate.s,\n         set = \"FluSurv\") %>%\n  select(location_name, ts_week, value, set)\n\nili_plt <- ilinet_full %>% \n  mutate(value = unweighted.s,\n          set = \"ILI\") %>%\n  select(location_name, ts_week, value, set)\n\nhhs_plt <- flu_HHS_full %>% \n  mutate(value = log(hosp_inc+0.0001),\n          set = \"HHS\") %>%\n  select(location_name, ts_week, value, set)\n\nnrevss_plt <- nrevss_full %>% \n  mutate(value = Apos.s,\n          set = \"NREVSS\") %>%\n  select(location_name, ts_week, value, set)\n\n\nall_plts <- rbind(fs_plt, ili_plt, hhs_plt, nrevss_plt)\nall_plts$set <- ordered(factor(all_plts$set), levels = c(\"FluSurv\", \"ILI\", \"NREVSS\", \"HHS\"))\n\nggplot() +\ngeom_tile(data=all_plts,\n          aes(ts_week, location_name, fill = value)) +\nxlab(\" \") +\nviridis::scale_fill_viridis(paste0(\" \"),\n                             discrete=F,\n                             option = \"turbo\",\n                             direction = -1,\n                             na.value = \"white\") +\nylab(\"Location\") +\nxlab(\"Weekly Timesteps (2010-2023)\") +\nfacet_wrap(~set, ncol = 4) +\ntheme(panel.grid.minor = element_blank(),\n      panel.grid.major = element_blank(),\n      panel.background = element_blank(),\n      plot.background = element_blank(),\n      panel.border = element_blank(),\n      legend.title = element_text(size = 16, face = \"bold\", hjust=0.5),\n      legend.text = element_text(size=10, face=\"bold\"),\n      strip.text = element_text(size=16, face=\"bold\"),\n      strip.background = element_blank(),\n      legend.position=\"none\", \n      legend.direction = \"horizontal\",\n      legend.box = \"horizontal\",\n      axis.text.y = element_text(face=\"bold\", size=5),\n      axis.text.x = element_text(face=\"bold\", size=12, vjust=0.5,\n                                 hjust=1, angle=90),\n      axis.title.x = element_text(size=12, face=\"bold\"),\n      axis.title.y = element_text(size=18, face=\"bold\"),\n      plot.title = element_text(size=18, face=\"bold\", hjust=0.5)) +\nguides(color = guide_legend(title.position = \"top\", label.position = \"bottom\"))"
  },
  {
    "objectID": "cons_index.html",
    "href": "cons_index.html",
    "title": "f(l)usion Workflow",
    "section": "",
    "text": "Construction\n\nScripts showing major steps steps in f(l)usion model development.\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Updated - Oldest\n        \n         \n          Updated - Newest\n        \n     \n  \n\n\n\n\n\n\n\nModel Inference\n\n\n13 min\n\n\nConstructing formula and running the model.\n\n\n\n\nJun 11, 2023\n\n\n\n\n\n\n\n\n\n\nData Organization\n\n\n12 min\n\n\nFormatting data as list() objects and DataStacks for model input.\n\n\n\n\nJun 11, 2023\n\n\n\n\n\n\n\n\n\n\nPreprocessing\n\n\n10 min\n\n\nImport and wrangle mutlisourced influenza observations\n\n\n\n\nJun 11, 2023\n\n\n\n\n\n\n\n\n\n\nModel Results\n\n\n0 min\n\n\nModel diagnostics and parameter interpretation\n\n\n\n\nJun 11, 2023\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About flusion",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "construction/model/model.html",
    "href": "construction/model/model.html",
    "title": "Model Inference",
    "section": "",
    "text": "Having completed data preprocessing and data organization, a formula is constructed and the model run.\nNote: This script requires that both the data Preprocessing and the Data Organization have already been completed with all resulting objects available in the working environment.\n\n\n\\begin{align}\n\\textit{y}_{1\\textit{st}}  &= \\beta_0 + \\beta_1{Pop} + \\varphi_{\\textit{t}} + \\textit{W}_1(\\textit{st}) \\nonumber \\\\\n\\textit{y}_{2\\textit{st}}|\\textit{y}_{1\\textit{st}}  &= \\beta_0 + \\beta_2{Pop} + \\gamma_{seas} + \\varphi_{\\textit{t}} +\\delta_{\\textit{st}} + \\textit{W}_2(\\textit{st}) + \\alpha_1 \\cdot \\textit{W}_1(\\textit{st}) \\nonumber \\\\\n\\textit{y}_{3\\textit{st}}|\\textit{y}_{1\\textit{st}}, \\textit{y}_{2\\textit{st}}  &= \\beta_0 + \\beta_3{Pop} + \\varphi_{\\textit{t}} + \\alpha_2 \\cdot \\gamma_{seas} + \\alpha_3 \\cdot \\textit{W}_1(\\textit{st}) + \\alpha_4 \\cdot \\delta_{\\textit{st}} + \\alpha_5 \\cdot \\textit{W}_2(\\textit{st}) + \\textit{W}_3(\\textit{st}) \\nonumber \\\\\n\\nonumber\n\\end{align}\n\n\n\n\\textit{s} (\\textit{s} = 1, 2, 3, \\ldots,56) are U.S. States and Territories\n\n\\textit{t} are time steps (yearly for spatial effects (\\textit{W}_(\\textit{st}))\n\n\\textit{y}_{1\\textit{st}} is the percent infected from the ILI data set (Level 1)\n\n\\textit{y}_{2\\textit{st}} is the percent confirmed positive Influenza A from NREVSS (Level 2)\n\n\\textit{y}_{3\\textit{st}} is hospital incidence from HHS (Level 3)\n\n\\beta_0’s are level-specific intercepts\n\n\\beta_2{Pop} are level-specific population estimates for each state\n\n\\textit{W}_(\\textit{st}) are BYM space-time effects specific to each level (1,2,3)\n\n\\gamma_{seas} is a week-based seasonal effect estimated from NREVSS\n\n\\delta_{\\textit{st}} is a space-time interaction (STI) term estimated from NREVSS\n\n\\varphi_{\\textit{t}} is a second-order random walk estimated from FluSurv data\n\n\n\n\n\n\\alpha_1 quantifies interaction between the ILI spatial effect (\\textit{W}_1(\\textit{st}) and NREVSS\n\n\\alpha_2 quantifies interaction between the NREVSS seasonal effect (\\gamma_{seas}) and HHS data\n\n\\alpha_3 quantifies interaction between the ILI spatial effect (\\textit{W}_1(\\textit{st}) and NREVSS\n\n\\alpha_4 quantifies interaction between the NREVSS STI effect (\\delta_{\\textit{st}}) and HHS\n\n\\alpha_5 quantifies interaction between the NREVSS spatial effect (\\textit{W}_2(\\textit{st}) and HHS"
  },
  {
    "objectID": "construction/results/results.html",
    "href": "construction/results/results.html",
    "title": "Model Results",
    "section": "",
    "text": "Compare model inputs and outputs\n\n\n\n\n\nNational Totals"
  },
  {
    "objectID": "construction/results/results.html#flusurv",
    "href": "construction/results/results.html#flusurv",
    "title": "Model Results",
    "section": "FluSurv",
    "text": "FluSurv"
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore the Data",
    "section": "",
    "text": "This page will show plots and figures describing the contents of the f(l)usion data set.\n\n\n\n\nShow code\nget_fusion <- function(url) {\n  library(readr)\n  df <- read_csv(url)\n  return(df)\n}\n\nhub_url <- \"https://github.com/JMHumphreys/flusion/raw/main/flusion/flusion_v1.csv\"\n\nmyFlusion <- as.data.frame(get_fusion(hub_url))\n\n\nhead(myFlusion)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nepiweek\nabbreviation\nlocation\nlocation_name\nq_0.025\nq_0.25\nq_0.50\nq_0.75\nq_0.975\n\n\n\n\n2010-10-09\n2010\n40\nAL\n01\nAlabama\n0.13\n0.43\n0.80\n1.48\n4.83\n\n\n2010-10-09\n2010\n40\nAK\n02\nAlaska\n0.04\n0.14\n0.26\n0.48\n1.58\n\n\n2010-10-09\n2010\n40\nAZ\n04\nArizona\n2.68\n8.71\n16.12\n29.72\n93.15\n\n\n2010-10-09\n2010\n40\nAR\n05\nArkansas\n0.08\n0.25\n0.47\n0.87\n2.82\n\n\n2010-10-09\n2010\n40\nCA\n06\nCalifornia\n1.81\n5.89\n10.93\n20.24\n64.55\n\n\n2010-10-09\n2010\n40\nCO\n08\nColorado\n1.12\n3.65\n6.77\n12.55\n40.19\n\n\n\n\n\n\n\n\n\ndate: Date of the reported epidemiological week (epiweek) based on a Saturday start.\n\nyear: Year of estimate\n\nepiweek: The epidemiological week\n\nabbreviation: U.S. State or Territory abbreviation.\n\nlocation: Numeric location code based on FIPS.\n\nlocation_name: Name of U.S. State or Territory.\n\nColumns beginning with q_ provide the 0.025, 0.25, 0.5, 0.75, and 0.975 quantiles for estimated flu hospitalizations.\n\n\n\n\n\n\n\nShow code\nlibrary(tidyverse)\noptions(dplyr.summarise.inform = FALSE, show_col_types = FALSE)\n\nnatl_sums <- myFlusion %>%\n  group_by(date) %>%\n  summarise(Q0.25 = sum(q_0.25),\n            Q0.50 = sum(q_0.50),\n            Q0.75 = sum(q_0.75))\n\n\nggplot(natl_sums, aes(date, Q0.50)) +  \n  geom_ribbon(aes(ymin=Q0.25, ymax=Q0.75),fill=\"steelblue\", alpha = 0.8) +\n  geom_line(linewidth = 0.5) +\n  scale_x_date(date_breaks = \"6 month\", date_labels = \"%b-%Y\") +\n  ylab(\"Estimated Hospitalizations\") +\n  xlab(\" \") +\n  theme_minimal() +\n  theme(plot.margin = unit(c(2,0.1,2,0.1), \"cm\"),\n        panel.grid.minor = element_line(color = \"gray90\", linewidth = 0.25, linetype = 1),\n        panel.grid.major = element_line(color = \"gray60\", linewidth = 0.5, linetype = 1),\n        panel.background = element_blank(),\n        plot.background = element_blank(),\n        legend.position=\"none\",\n        legend.text = element_text(size=12, face=\"bold\"),\n        legend.title = element_text(size=16, face=\"bold\"),\n        axis.title.x =  element_text(size=16, face=\"bold\"),\n        axis.title.y = element_text(size=16, face=\"bold\"),\n        axis.text.x =  element_text(size=14, face=\"bold\", angle=60, hjust=1),\n        axis.text.y = element_text(size=12, face=\"bold\"),\n        plot.title = element_text(size=22, face=\"bold\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nset.seed(123)\nrandom_states <- sample(myFlusion$abbreviation, size=4)\n\nstates_plot <- myFlusion %>%\n  filter(abbreviation %in% random_states)\n\nggplot(states_plot, aes(date, q_0.50)) +  \n  geom_ribbon(aes(ymin=q_0.025, ymax=q_0.975),fill=\"steelblue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin=q_0.25, ymax=q_0.75),fill=\"steelblue\", alpha = 0.5) +\n  geom_line(linewidth = 0.5) +\n  scale_x_date(date_breaks = \"6 month\", date_labels = \"%b-%Y\") +\n  facet_grid(rows = vars(location_name), scales = \"free_y\") +\n  ylab(\"Estimated Hospitalizations\") +\n  xlab(\" \") +\n  theme_minimal() +\n  theme(plot.margin = unit(c(0.1,0.1,0.1,0.1), \"cm\"),\n        panel.grid.minor = element_line(color = \"gray90\", linewidth = 0.25, linetype = 1),\n        panel.grid.major = element_line(color = \"gray60\", linewidth = 0.5, linetype = 1),\n        panel.background = element_blank(),\n        plot.background = element_blank(),\n        strip.text = element_text(size=14, face=\"bold\"),\n        strip.background = element_blank(),\n        legend.position=\"none\",\n        legend.title = element_text(size=16, face=\"bold\"),\n        axis.title.x =  element_text(size=16, face=\"bold\"),\n        axis.title.y = element_text(size=16, face=\"bold\"),\n        axis.text.x =  element_text(size=12, face=\"bold\", angle=60, hjust=1),\n        axis.text.y = element_text(size=12, face=\"bold\"),\n        plot.title = element_text(size=22, face=\"bold\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nset.seed(111)\nrandom_states <- sample(myFlusion$abbreviation, size=4)\n\nrandom_yr <- sample(myFlusion$year, size=1)\n\n\n\nstates_plot_yr <- myFlusion %>%\n  filter(abbreviation %in% random_states,\n         year == random_yr | year == (random_yr + 1))\n\nggplot(states_plot_yr, aes(date, q_0.50)) +  \n  geom_ribbon(aes(ymin=q_0.025, ymax=q_0.975),fill=\"steelblue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin=q_0.25, ymax=q_0.75),fill=\"steelblue\", alpha = 0.5) +\n  geom_line(linewidth = 0.5) +\n  scale_x_date(date_breaks = \"6 month\", date_labels = \"%b-%Y\") +\n  facet_grid(rows = vars(location_name), scales = \"free_y\") +\n  ylab(\"Estimated Hospitalizations\") +\n  xlab(\" \") +\n  theme_minimal() +\n  theme(plot.margin = unit(c(0.1,0.1,0.1,0.1), \"cm\"),\n        panel.grid.minor = element_line(color = \"gray90\", linewidth = 0.25, linetype = 1),\n        panel.grid.major = element_line(color = \"gray60\", linewidth = 0.5, linetype = 1),\n        panel.background = element_blank(),\n        plot.background = element_blank(),\n        strip.text = element_text(size=14, face=\"bold\"),\n        strip.background = element_blank(),\n        legend.position=\"none\",\n        legend.title = element_text(size=16, face=\"bold\"),\n        axis.title.x =  element_text(size=16, face=\"bold\"),\n        axis.title.y = element_text(size=16, face=\"bold\"),\n        axis.text.x =  element_text(size=16, face=\"bold\"),\n        axis.text.y = element_text(size=12, face=\"bold\"),\n        plot.title = element_text(size=22, face=\"bold\"))"
  },
  {
    "objectID": "construction/preprocessing/preprocessing.html#covid19-rpihc",
    "href": "construction/preprocessing/preprocessing.html#covid19-rpihc",
    "title": "Preprocessing",
    "section": "COVID19 RPIHC",
    "text": "COVID19 RPIHC\nDownloading the COVID-19 Reported Patient Impact and Hospital Capacity by State Timeseries from https://healthdata.gov/.\n\n\nHide code\nurl <- \"https://healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD\"\nfilename <- \"D:/Github/flusion/data/flu_HHS.csv\"\n\ndownload_file(url, filename)\n\n\nRead and wrangle RPIHC:\n\n\nHide code\nflu_HHS <- fread(\"D:/Github/flusion/data/flu_HHS.csv\") %>%\n  mutate(abbreviation = state,\n         date = as_date(date) - 1, #1-day prior, per fluSight truth\n         year = year(date),\n         epiweek = epiweek(date)) %>%\n  group_by(abbreviation, year, epiweek) %>%\n  summarise(hosp_inc = sum(previous_day_admission_influenza_confirmed))\n\nunique(duplicated(flu_HHS))\n\n\n[1] FALSE\n\n\nHide code\ndim(flu_HHS)\n\n\n[1] 9346    4\n\n\nHide code\nrange(flu_HHS$year)\n\n\n[1] 2019 2023\n\n\nHide code\nhead(flu_HHS)\n\n\n\n\n\n\nabbreviation\nyear\nepiweek\nhosp_inc\n\n\n\n\nAK\n2020\n13\nNA\n\n\nAK\n2020\n14\nNA\n\n\nAK\n2020\n15\nNA\n\n\nAK\n2020\n16\nNA\n\n\nAK\n2020\n17\nNA\n\n\nAK\n2020\n18\nNA"
  },
  {
    "objectID": "explain.html",
    "href": "explain.html",
    "title": "What is flusion?",
    "section": "",
    "text": "f(l)usion is a data set that provides estimates for hospitalizations that resulted from influenza. The data is estimated by a joint spatiotemporal model that joins (fuses) data from FluSurv, the Influenza Like Illness (ILI) data set, the NREVSS data set, and HHS reported incidence to produce estimates. In a sense, flusion can be thought of as a historical reconstruction of past hospitalization based on signals (patterns and trends) captured in the contributing data sources."
  },
  {
    "objectID": "explain.html#whats-it-good-for",
    "href": "explain.html#whats-it-good-for",
    "title": "What is flusion?",
    "section": "What’s it good for?",
    "text": "What’s it good for?\nFlusion is intended to provide a complete and continuous source of data to train and support influenza forecasting modeling. It is an analytic product to support other analytic products.\n\n\n\nFlusion in a snapshot: Arrows represent how information is passed between data-specific submodels"
  },
  {
    "objectID": "demo1.html",
    "href": "demo1.html",
    "title": "Flu Season 2022-2023",
    "section": "",
    "text": "This is a quick demonstration of using flusion data to forecast 2022-2023 influenza hospitalizations across all U.S. States and Territories. The demo includes matching flusion to truth data from FluSight, constructing a non-spatial randomwalk model, and then comparing the predicted values to truth data."
  },
  {
    "objectID": "demo1.html#analysis-setup",
    "href": "demo1.html#analysis-setup",
    "title": "Flu Season 2022-2023",
    "section": "2 Analysis Setup",
    "text": "2 Analysis Setup\n\n2.1 Libraries\nLoading libraries.\n\n\nHide code\n#wrangling\nlibrary(tidyverse)\nlibrary(lubridate)\n\n#inference\nlibrary(INLA)\n#use adaptive search algorithm\ninla.setOption(inla.mode= \"experimental\")\n\noptions(dplyr.summarise.inform = FALSE)\n\n\n\n\n2.2 Observation Data\nflusion\n\n\nHide code\n#function to downlaod file\nget_data <- function(url) {\n  df <- read_csv(url)\n  return(df)\n}\n\nflusion_url <- \"https://github.com/JMHumphreys/flusion/raw/main/flusion/flusion_v1.csv\"\nflusion <- get_data(flusion_url)\nhead(flusion)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nepiweek\nabbreviation\nlocation\nlocation_name\nq_0.025\nq_0.25\nq_0.50\nq_0.75\nq_0.975\n\n\n\n\n2010-10-09\n2010\n40\nAL\n01\nAlabama\n0.13\n0.43\n0.80\n1.48\n4.83\n\n\n2010-10-09\n2010\n40\nAK\n02\nAlaska\n0.04\n0.14\n0.26\n0.48\n1.58\n\n\n2010-10-09\n2010\n40\nAZ\n04\nArizona\n2.68\n8.71\n16.12\n29.72\n93.15\n\n\n2010-10-09\n2010\n40\nAR\n05\nArkansas\n0.08\n0.25\n0.47\n0.87\n2.82\n\n\n2010-10-09\n2010\n40\nCA\n06\nCalifornia\n1.81\n5.89\n10.93\n20.24\n64.55\n\n\n2010-10-09\n2010\n40\nCO\n08\nColorado\n1.12\n3.65\n6.77\n12.55\n40.19\n\n\n\n\n\n\nFluSight truth data\n\n\nHide code\n#FluSight: 2023-06-12\nflusight_url <- \"https://github.com/cdcepi/Flusight-forecast-data/raw/master/data-truth/truth-Incident%20Hospitalizations.csv\" \nflusight_truth <- get_data(flusight_url)\nhead(flusight_truth)\n\n\n\n\n\n\ndate\nlocation\nlocation_name\nvalue\n\n\n\n\n2020-01-11\n01\nAlabama\n0\n\n\n2020-01-11\n15\nHawaii\n0\n\n\n2020-01-11\n18\nIndiana\n0\n\n\n2020-01-11\n27\nMinnesota\n0\n\n\n2020-01-11\n30\nMontana\n0\n\n\n2020-01-11\n37\nNorth Carolina\n0\n\n\n\n\n\n\n\n\n2.3 Join Data\n\n\nHide code\nrange(flusion$date)\n\n\n[1] \"2010-10-09\" \"2023-06-03\"\n\n\nHide code\nrange(flusight_truth$date) #1 week added since flusion.v1\n\n\n[1] \"2020-01-11\" \"2023-06-10\"\n\n\nHide code\nflusight_truth <- flusight_truth %>%\n  mutate(truth = value) %>%\n  select(date, location, truth)\n\ncomb_data <- left_join(flusion, flusight_truth, by = c(\"date\", \"location\"))\n\ncomb_data <- comb_data %>%\n  mutate(ts_weeks = as.integer(as.factor(year + epiweek/52)))\n\nhead(comb_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nepiweek\nabbreviation\nlocation\nlocation_name\nq_0.025\nq_0.25\nq_0.50\nq_0.75\nq_0.975\ntruth\nts_weeks\n\n\n\n\n2010-10-09\n2010\n40\nAL\n01\nAlabama\n0.13\n0.43\n0.80\n1.48\n4.83\nNA\n1\n\n\n2010-10-09\n2010\n40\nAK\n02\nAlaska\n0.04\n0.14\n0.26\n0.48\n1.58\nNA\n1\n\n\n2010-10-09\n2010\n40\nAZ\n04\nArizona\n2.68\n8.71\n16.12\n29.72\n93.15\nNA\n1\n\n\n2010-10-09\n2010\n40\nAR\n05\nArkansas\n0.08\n0.25\n0.47\n0.87\n2.82\nNA\n1\n\n\n2010-10-09\n2010\n40\nCA\n06\nCalifornia\n1.81\n5.89\n10.93\n20.24\n64.55\nNA\n1\n\n\n2010-10-09\n2010\n40\nCO\n08\nColorado\n1.12\n3.65\n6.77\n12.55\n40.19\nNA\n1\n\n\n\n\n\n\nHide code\ntail(comb_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nepiweek\nabbreviation\nlocation\nlocation_name\nq_0.025\nq_0.25\nq_0.50\nq_0.75\nq_0.975\ntruth\nts_weeks\n\n\n\n\n2023-06-03\n2023\n22\nWA\n53\nWashington\n0.18\n0.95\n2.31\n5.58\n29.93\n19\n659\n\n\n2023-06-03\n2023\n22\nWV\n54\nWest Virginia\n0.08\n0.44\n1.05\n2.55\n13.62\n5\n659\n\n\n2023-06-03\n2023\n22\nWI\n55\nWisconsin\n0.20\n1.05\n2.54\n6.13\n32.45\n7\n659\n\n\n2023-06-03\n2023\n22\nWY\n56\nWyoming\n0.07\n0.40\n1.00\n2.47\n13.83\n1\n659\n\n\n2023-06-03\n2023\n22\nPR\n72\nPuerto Rico\n0.14\n0.74\n1.79\n4.33\n23.44\n80\n659\n\n\n2023-06-03\n2023\n22\nVI\n78\nVirgin Islands\n0.00\n0.06\n0.25\n0.97\n12.79\n0\n659\n\n\n\n\n\n\n\n\n2.4 Overlap Period\nQuick plot to compare flusion estimates to FluSight truth.\n\n\nHide code\noverlap_data <- comb_data %>%\n  filter(date >= min(flusight_truth$date) &\n         date <= max(flusight_truth$date))\n\n\noverlap_natl <- overlap_data %>%\n  group_by(date) %>%\n  summarise(flusion = sum(q_0.50),\n            truth = sum(truth, na.rm=T))\n\noverlap_natl <- reshape2::melt(overlap_natl, \"date\")\n\nggplot(overlap_natl, aes(date, value)) +\n  geom_bar(stat=\"identity\") +\n  facet_grid(rows = vars(variable)) +\n  scale_x_date(date_breaks = \"6 month\", date_labels = \"%b-%Y\") +\n  theme_classic() +\n  ylab(\"Hospitalizations\") +\n  xlab(\" \") +\n  theme_minimal() +\n  theme(plot.margin = unit(c(2,0.1,2,0.1), \"cm\"),\n        panel.grid.minor = element_line(color = \"gray90\", linewidth = 0.25, linetype = 1),\n        panel.grid.major = element_line(color = \"gray60\", linewidth = 0.5, linetype = 1),\n        panel.background = element_blank(),\n        plot.background = element_blank(),\n        strip.text = element_text(size=14, face=\"bold\"),\n        strip.background = element_blank(),\n        legend.position=\"none\",\n        legend.text = element_text(size=12, face=\"bold\"),\n        legend.title = element_text(size=16, face=\"bold\"),\n        axis.title.x =  element_text(size=16, face=\"bold\"),\n        axis.title.y = element_text(size=16, face=\"bold\"),\n        axis.text.x =  element_text(size=14, face=\"bold\", angle=60, hjust=1),\n        axis.text.y = element_text(size=12, face=\"bold\"),\n        plot.title = element_text(size=22, face=\"bold\"))"
  },
  {
    "objectID": "demo1.html#training-vs-testing",
    "href": "demo1.html#training-vs-testing",
    "title": "Flu Season 2022-2023",
    "section": "3 Training vs Testing",
    "text": "3 Training vs Testing\nBreak data into testing and training sets. Attempt to forecast the most recent flu season 2022-2033.\n####Notes:\n+ Y is the target response variable in the demo model\n+ Dates between Oct 2022 through May 2023 as coded as unknown (NA)\n+ The demo model will attempt to predict the NA’s\n\n\nHide code\ncomb_data$Y <- ifelse(comb_data$year >= 2022 & comb_data$epiweek >= 40, NA, comb_data$q_0.50)"
  },
  {
    "objectID": "demo1.html#organize-data",
    "href": "demo1.html#organize-data",
    "title": "Flu Season 2022-2023",
    "section": "4 Organize Data",
    "text": "4 Organize Data\n\n\nHide code\ncomb_data <- comb_data %>%\n  mutate(intercept = 1,   #intercept\n         Y = round(Y, 0)) #round to integer count data\n         \n# copy location index\ncomb_data$Region.1 <- as.integer(comb_data$location)\n\n#copies of weekly time index\ncomb_data$ts_weeks.1 <- comb_data$ts_weeks.2 <- comb_data$ts_weeks.3 <- comb_data$ts_weeks"
  },
  {
    "objectID": "demo1.html#model",
    "href": "demo1.html#model",
    "title": "Flu Season 2022-2023",
    "section": "5 Model",
    "text": "5 Model\n\n\nHide code\n#prior\npc.prior = list(prec = list(prior=\"pc.prec\", \n                            param = c(1, 0.5)))\n\n#formula\nform.rw <- Y ~ -1 + intercept + #use custom intercept\n  f(ts_weeks.1,   #random walk + noise   \n    constr=TRUE,\n    model=\"rw2\",\n    hyper=pc.prior) +\n  f(ts_weeks.2,  #extra variation outside of rw time and linear trends     \n    constr=TRUE,\n    model=\"iid\",\n    hyper=pc.prior) +\n  f(Region.1, #state-level variation          \n    constr=TRUE,\n    model=\"iid\",\n    hyper=pc.prior) +\n  ts_weeks.3    # linear trend\n\n#run model\n\nrw.mod = inla(form.rw, #formula\n                     data = comb_data, #data \n                     family = c(\"nbinomial\"), #negative binomial\n                     verbose = FALSE, \n                     quantiles = c(0.05, 0.25, 0.5, 0.75, 0.95),\n                     control.fixed = list(prec = 1, \n                                          prec.intercept = 1), \n                     control.predictor = list(\n                                        compute = TRUE, \n                                              link = 1), \n                     control.inla = list(strategy=\"adaptive\", \n                                                       int.strategy = \"eb\"), \n                     control.compute=list(dic = F, cpo = F, waic = F))"
  },
  {
    "objectID": "demo1.html#national-prediction",
    "href": "demo1.html#national-prediction",
    "title": "Flu Season 2022-2023",
    "section": "6 National Prediction",
    "text": "6 National Prediction\nThe bar chart indicates truth, solid line is the predicted 0.5 quantile, and shaded bands provide the 95 credible interval.\n\n\nHide code\nmodel_out <- rw.mod$summary.fitted.values[,c(3:7)]\nnames(model_out) <- c(\"q0.05\", \"q0.25\", \"q0.5\", \"q0.75\", \"q0.95\")\n\ncomb_data_pred <- cbind(comb_data, model_out)\n\nrw_natl <- comb_data_pred %>%\n  filter(is.na(Y) == TRUE) %>%\n  group_by(date) %>%\n  summarise(Q0.05 = sum(q0.05),\n            Q0.25 = sum(q0.25),\n            Q0.5 = sum(q0.5),\n            Q0.75 = sum(q0.75),\n            Q0.95 = sum(q0.95),\n            truth = sum(truth, na.rm=T))\n\n\nggplot(rw_natl, aes(date, truth)) +\n  geom_bar(stat=\"identity\", fill=\"tan\") +\n  geom_ribbon(aes(ymin=Q0.05, ymax=Q0.95),fill=\"steelblue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin=Q0.25, ymax=Q0.75),fill=\"steelblue\", alpha = 0.5) +\n  geom_line(data=rw_natl,\n            aes(date, Q0.5)) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%Y\") +\n  theme_classic() +\n  ylab(\"Hospitalizations\") +\n  xlab(\" \") +\n  theme_minimal() +\n  theme(plot.margin = unit(c(2,0.1,2,0.1), \"cm\"),\n        panel.grid.minor = element_line(color = \"gray90\", linewidth = 0.25, linetype = 1),\n        panel.grid.major = element_line(color = \"gray60\", linewidth = 0.5, linetype = 1),\n        panel.background = element_blank(),\n        plot.background = element_blank(),\n        strip.text = element_text(size=14, face=\"bold\"),\n        strip.background = element_blank(),\n        legend.position=\"none\",\n        legend.text = element_text(size=12, face=\"bold\"),\n        legend.title = element_text(size=16, face=\"bold\"),\n        axis.title.x =  element_text(size=16, face=\"bold\"),\n        axis.title.y = element_text(size=16, face=\"bold\"),\n        axis.text.x =  element_text(size=14, face=\"bold\", angle=60, hjust=1),\n        axis.text.y = element_text(size=12, face=\"bold\"),\n        plot.title = element_text(size=22, face=\"bold\"))"
  },
  {
    "objectID": "demo1.html#random-states",
    "href": "demo1.html#random-states",
    "title": "Flu Season 2022-2023",
    "section": "7 Random States",
    "text": "7 Random States\n\n\nHide code\nset.seed(34)\nrandom_states <- sample(comb_data_pred$abbreviation, size=4)\n\nstates_plot <- comb_data_pred %>%\n  filter(abbreviation %in% random_states,\n         is.na(Y) == TRUE)\n\n\nggplot(states_plot, aes(date, truth)) +\n  geom_bar(stat=\"identity\", fill=\"tan\") +\n  geom_ribbon(aes(ymin=q0.05, ymax=q0.95),fill=\"steelblue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin=q0.25, ymax=q0.75),fill=\"steelblue\", alpha = 0.5) +\n  geom_line(data=states_plot,\n            aes(date, q0.5)) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%Y\") +\n  facet_grid(rows = vars(location_name), scales = \"free_y\") +\n  theme_classic() +\n  ylab(\"Hospitalizations\") +\n  xlab(\" \") +\n  theme_minimal() +\n  theme(panel.grid.minor = element_line(color = \"gray90\", linewidth = 0.25, linetype = 1),\n        panel.grid.major = element_line(color = \"gray60\", linewidth = 0.5, linetype = 1),\n        panel.background = element_blank(),\n        plot.background = element_blank(),\n        strip.text = element_text(size=14, face=\"bold\"),\n        strip.background = element_blank(),\n        legend.position=\"none\",\n        legend.text = element_text(size=12, face=\"bold\"),\n        legend.title = element_text(size=16, face=\"bold\"),\n        axis.title.x =  element_text(size=16, face=\"bold\"),\n        axis.title.y = element_text(size=16, face=\"bold\"),\n        axis.text.x =  element_text(size=14, face=\"bold\", angle=60, hjust=1),\n        axis.text.y = element_text(size=12, face=\"bold\"),\n        plot.title = element_text(size=22, face=\"bold\"))"
  }
]