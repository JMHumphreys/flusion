---
title: "Preprocessing"
description: "Import and wrangle mutlisourced influenza observations"
format:
  html:
    df-print: kable
    code-fold: show
    code-summary: "Hide code"
    code-overflow: wrap
    toc-title: Page Contents
    toc: true
    toc-depth: 2
    toc-location: right
    number-sections: false
    html-math-method: katex
    css: styles.css
    theme: flatly
    smooth-scroll: true
editor_options: 
  chunk_output_type: console
---

```{=html}
<style type="text/css">

body, td {
   font-size: 13pt;
}
code.r{
  font-size: 9pt;
}
pre {
  font-size: 11pt
}
</style>
```
# Preliminaries
 
Setup working environment and loading necessary packages.

## Libraries

```{r warning=FALSE, message=FALSE}
#wrangling
library(tidyverse)
library(lubridate)
library(data.table, include.only = "fread")
library(cdcfluview)
library(yaml)

#spatial
library(sp)
library(sf)
library(spdep)
library(rgeos)
library(igraph)
library(maptools)
library(mapproj)
library(CovidCAR)
#devtools::install_github("JMHumphreys/CovidCAR")

#messages
library(cli)

#inference
library(INLA)

#Utilities
#source("./R/utilities.R")

options(dplyr.summarise.inform = FALSE)

#function
download_file <- function(url, filename) {
  download.file(url, destfile = filename, method = "auto", quiet = FALSE, mode = "wb")
}
```

# Observation Data

## FluSurv

Build a flu hospitalization data file from individual state reports and all available years. The *hospitalizations()* function from the **cdcfluview** package does most of the work by querying [FluView](https://gis.cdc.gov/GRASP/Fluview/FluHospRates.html), but seems only to be able to take small bites at a time.

```{r eval=TRUE}
myRegions <- surveillance_areas() 

flusurv_all <- do.call(rbind, lapply(seq_len(dim(myRegions)[1]), function(i) {
  hospitalizations(surveillance_area = myRegions$surveillance_area[i], region = myRegions$region[i])
}))
```

Wrangle Flusurv data:\
Note that the **cdcfluview** package only includes through Spring of 2020. Because of this, the data is filtered at 2019 and a static file manually downloaded from FluView with more recnt reports (eventually this data will be moved to www.healthdata.gov).

```{r warning=FALSE}
range(flusurv_all$year)

flusurv <- flusurv_all %>%
  filter(age_label == "Overall",
         region != "Entire Network",
         year >= 2010 & year <= 2019) %>% #the pkg fails on dates after 2020,ugh
  mutate(location_name = region,
         network = surveillance_area,
         weeklyrate = as.numeric(weeklyrate),
         epiweek = year_wk_num) %>%
    select(location_name, year, epiweek, network, rate, weeklyrate)
  
#manual download from site 2023-06-01
flusurv_2020 <- fread("D:/Github/flusion/data/FluSurveillance_2020.csv") %>%
  rename_all(~gsub(" |-", "", .)) %>%
  filter(AGECATEGORY == "Overall",
         SEXCATEGORY == "Overall",
         RACECATEGORY == "Overall",
         CATCHMENT != "Entire Network",
         MMWRYEAR >= 2020) %>% #Prior to this date was downloaded in code above
  mutate(location_name = CATCHMENT,
         network = NETWORK,
         year = MMWRYEAR,
         epiweek = MMWRWEEK,
         rate = CUMULATIVERATE,
         weeklyrate = as.numeric(WEEKLYRATE)) %>%
    select(location_name, year, epiweek, network, rate, weeklyrate)

#Join date ranges and scale weeklyrate
flusurv = rbind(flusurv, flusurv_2020)
flusurv$weeklyrate.s = as.numeric(scale(flusurv$weeklyrate, scale = T, center=T))

#combine NY data
flusurv$location_name[flusurv$location_name == "New York - Albany"] = "New York"
flusurv$location_name[flusurv$location_name == "New York - Rochester"] ="New York"

flusurv <- flusurv %>%
  group_by(location_name, year, epiweek) %>%
  summarise(rate = mean(rate, na.rm=T),
            weeklyrate = mean(weeklyrate, na.rm=T),
            weeklyrate.s = mean(weeklyrate.s, na.rm=T))


#Check for duplicates
unique(duplicated(flusurv))
dim(flusurv)
head(flusurv)
```

Same FluSurv process as above, but now for the Full Network reports

```{r}
flusurv_en <- flusurv_all %>%
  filter(age_label == "Overall",
         region == "Entire Network",
         year >= 2010 & year <= 2019) %>% #the pkg fails on dates after 2020,ugh
  mutate(location_name = region,
         network = surveillance_area,
         epiweek = year_wk_num) %>%
    select(location_name, year, epiweek, network, rate, weeklyrate)

flusurv_en2020 <- fread("D:/Github/flusion/data/FluSurveillance_2020.csv") %>%
  rename_all(~gsub(" |-", "", .)) %>%
  filter(AGECATEGORY == "Overall",
         SEXCATEGORY == "Overall",
         RACECATEGORY == "Overall",
         CATCHMENT == "Entire Network",
         MMWRYEAR >= 2020) %>% #the pkg fails on dates after 2020,ugh
  mutate(location_name = CATCHMENT,
         network = NETWORK,
         year = MMWRYEAR,
         epiweek = MMWRWEEK,
         rate = CUMULATIVERATE,
         weeklyrate = WEEKLYRATE) %>%
    select(location_name, year, epiweek, network, rate, weeklyrate)

#Join
flusurv_en <- rbind(flusurv_en, flusurv_en2020)
unique(duplicated(flusurv_en))
dim(flusurv_en)

head(flusurv_en)
```

## ILINet Surveillance Data

Influenza Like Illness (ILI) data using **cdcfluview** package. Unlike FluSurv, data is available 2010-2013.

```{r}
ilinet <- ilinet(region = "state") %>%
  mutate(location_name = region,
         epiweek = week,
         unweighted = as.numeric(unweighted_ili),
         unweighted.s = unweighted,
         total = ilitotal,
         providers = num_of_providers) %>%
  select(location_name, year, epiweek, unweighted, unweighted.s, total, providers)

# Clip to between 0.0001 and 99.999
ilinet$unweighted.s <- pmin(pmax(as.numeric(ilinet$unweighted.s), 0.0001), 99.9999)/100

# logit transform 
ilinet$unweighted.s <- log(ilinet$unweighted.s/(1-ilinet$unweighted.s))
range(ilinet$unweighted.s, na.rm=T)

unique(duplicated(ilinet))
dim(ilinet)
range(ilinet$year)
head(ilinet)
```

## COVID19 RPIHC

Downloading the COVID-19 Reported Patient Impact and Hospital Capacity by State Timeseries from https://healthdata.gov/.

```{r eval=TRUE, warning=FALSE, message=FALSE}
url <- "https://healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD"
filename <- "D:/Github/flusion/data/flu_HHS.csv"

download_file(url, filename)
```

Read and wrangle RPIHC:

```{r}

flu_HHS <- fread("D:/Github/flusion/data/flu_HHS.csv") %>%
  mutate(abbreviation = state,
         date = as_date(date) - 1, #1-day prior, per fluSight truth
         year = year(date),
         epiweek = epiweek(date)) %>%
  group_by(abbreviation, year, epiweek) %>%
  summarise(hosp_inc = sum(previous_day_admission_influenza_confirmed))

unique(duplicated(flu_HHS))
dim(flu_HHS)
range(flu_HHS$year)
head(flu_HHS)
```

## NREVSS

National Respiratory and Enteric Virus Surveillance System.

Again, unfortunately only available through a manual: https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html\
Files illustrated here were downloaded on June 2, 2023.

```{r warning=FALSE, message=FALSE}

nrevss.1 <- fread("D:/Github/flusion/data/WHO_NREVSS_Combined_prior_to_2015_16.csv") %>%
  rename_all(~gsub(" |-", "", .)) %>%
  mutate(location_name = REGION,
         year = YEAR,
         epiweek = WEEK,
         tot_perc = as.numeric(PERCENTPOSITIVE),
         Bpos = as.numeric(B),
         tot_samp = as.numeric(TOTALSPECIMENS),
         Apos = tot_perc - ((Bpos/tot_samp)*100)) %>%
  select(location_name, year, epiweek, Apos)


nrevss.2 <- fread("D:/Github/flusion/data/WHO_NREVSS_Clinical_Labs.csv") %>%
  rename_all(~gsub(" |-", "", .)) %>%
  mutate(location_name = REGION,
         year = YEAR,
         epiweek = WEEK,
         Apos = PERCENTA) %>%
  select(location_name, year, epiweek, Apos) #Apos = Influenza A positive

# Combine 
nrevss <- rbind(nrevss.1, nrevss.2)

# Replace "X" 
nrevss$Apos[nrevss$Apos == "X"] <- NA

# Clip to between 0.0001 and 99.999
nrevss$Apos <- pmin(pmax(as.numeric(nrevss$Apos), 0.0001), 99.9999)/100

# logit transform 
nrevss$Apos.s <- log(nrevss$Apos/(1-nrevss$Apos))
unique(duplicated(nrevss))
head(nrevss)
```

# Location Template

## Location Table

Location codes and population numbers from FluSight. Should really get varying census over time period, but these are a start.

```{r warning=FALSE, message=FALSE}
url <- "https://github.com/cdcepi/Flusight-forecast-data/raw/master/data-locations/locations.csv"
filename <- "D:/Github/flusion/data/locations.csv"

download_file(url, filename)
```

Read locations:

```{r}
locations <- fread("D:/Github/flusion/data/locations.csv") %>%
  select(-c(count_rate1per100k, count_rate2per100k)) %>%
  filter(location_name != "US") #remove aggregate group

head(locations)
```

# Template

Ensure all locations and times are represented in the analysis. Missing data are plugged with NA.

## Dates and Locations

```{r}
myYears <- seq(2010, 2023, by = 1)
week_nums <- 1:52

year_set <- lapply(myYears, function(year) {
  tmp_frame <- locations %>% mutate(year = year)
  
  weekly_set <- lapply(week_nums, function(week_num) {
    tmp_frame_wk <- tmp_frame %>% mutate(epiweek = week_num)
    return(tmp_frame_wk)
  })
  
  weekly_set <- do.call(rbind, weekly_set)
  return(weekly_set)
})

template <- do.call(rbind, year_set)

dim(template)
head(template) #all states and times represented

#most_recent <- max(subset(flu_HHS, year == 2023)$epiweek) #drop future dates
most_recent <- 22 #models were initiall fit with 2023-Epiweek-22
template$keep <- ifelse(template$year == 2023 & template$epiweek > most_recent, "drop", "keep")

template <- template %>% 
  filter(keep == "keep") %>%
  select(-keep)

unique(duplicated(template))
```

## Reduce for Testing

Running the analysis from 2010 through 2023-Epiweek-22.

```{r}
template <- template %>% filter(year >= 2010)
```

## Time Steps

An index with sequential timesteps.

```{r}
template <- template %>%
  arrange(year, epiweek) %>%
  mutate(ts_week = as.integer(as.factor(year + (epiweek/53))))


range(template$ts_week) #number of epiweeks
```

# Spatial Domian

Need to setup directories to use **CovidCAR** functions. Values here are arbitrary (need to add option to bypass to CovidCAR)

```{r warning=FALSE, message=FALSE}
setup_analysis(report_date = "2010-01-01", 
               training_period = 2*28, #days
               forecast_horizon = 28, #days
               output_dir = "D:/Github/flusion/data"
)
```

## Get Geographic Boundaries

```{r message=FALSE, warning=FALSE}
States <- download_boundaries(unit = "state")
class(States)

head(States@data[,c("Region", "State")]) #appended attributes  
```

## Adjacency

```{r warning=FALSE, message=FALSE, fig.width=8,fig.height=6}
nb_flusion = get_neighbors(States, connect=TRUE)
summary(nb_flusion)

#view
plot_neighbors(States, nb_flusion)

#convert to matrix
nb2INLA("J", nb_flusion)
J = inla.read.graph("J")
```

## Template Spatial Index

```{r}
template$Region =  with(States@data[,c("Region", "State")],
                       Region[match(
                        template$location_name,
                                 State)])
```

## Add Entire Network

Getting the flue weeklyrate from FluSurv. Not that this is only the time trend from FluSurv and is not loaction specific.

```{r warning=FALSE, message=FALSE}
en_match <- flusurv_en %>%
  group_by(year, epiweek) %>%
  summarise(en_est = mean(as.numeric(weeklyrate), na.rm=TRUE)) %>%
  select(year, epiweek, en_est)

# Clip to between 0.0001 and 99.999
en_match$en_est.s <- pmin(pmax(as.numeric(en_match$en_est), 0.0001), 99.9999)/100

# logit transform 
en_match$en_est.s <- round(log(en_match$en_est.s/(1-en_match$en_est.s)), 3)
range(en_match$en_est.s, na.rm=T)

template <- left_join(template, en_match, by = c("year", "epiweek"))
unique(duplicated(template))
```

## Space-Time Interaction Index

May not be used, but including with Template just in case.

```{r}
template$st_int <- as.integer(as.factor(paste0(template$Region, ".", template$ts_week)))
range(template$st_int)
```

# Join to Disease Data

Join observation data to the template. Times and locations without observations are coded as NA.

```{r}
#FluSurv
flusurv_full <- left_join(template, flusurv, by = c("location_name", "year", "epiweek")) 
flusurv_full$network[is.na(flusurv_full$network)] = "none"
unique(duplicated(flusurv_full))
head(flusurv_full) #times and locations w/out values assigned NA

#ILI Surveillance
ilinet_full <- left_join(template, ilinet, by = c("location_name", "year", "epiweek"))
unique(duplicated(ilinet_full))
head(ilinet_full)

#HHS 
flu_HHS_full <- left_join(template, flu_HHS, by = c("abbreviation", "year", "epiweek"))
unique(duplicated(flu_HHS_full))
unique(duplicated(flu_HHS_full[,c("ts_week", "Region")]))
head(flu_HHS_full)

#nrevss 
nrevss_full <- left_join(template, nrevss, by = c("location_name", "year", "epiweek"))
unique(duplicated(nrevss_full))
head(nrevss_full)
```

## View Coverage

Looking at holes in the data. Not interested in exact values, only comparing data coverage.

```{r fig.width=8, fig.height=8}
fs_plt <- flusurv_full %>% 
  mutate(value = weeklyrate.s,
         set = "FluSurv") %>%
  select(location_name, ts_week, value, set)

ili_plt <- ilinet_full %>% 
  mutate(value = unweighted.s,
          set = "ILI") %>%
  select(location_name, ts_week, value, set)

hhs_plt <- flu_HHS_full %>% 
  mutate(value = log(hosp_inc+0.0001),
          set = "HHS") %>%
  select(location_name, ts_week, value, set)

nrevss_plt <- nrevss_full %>% 
  mutate(value = Apos.s,
          set = "NREVSS") %>%
  select(location_name, ts_week, value, set)


all_plts <- rbind(fs_plt, ili_plt, hhs_plt, nrevss_plt)
all_plts$set <- ordered(factor(all_plts$set), levels = c("FluSurv", "ILI", "NREVSS", "HHS"))

ggplot() +
geom_tile(data=all_plts,
          aes(ts_week, location_name, fill = value)) +
xlab(" ") +
viridis::scale_fill_viridis(paste0(" "),
                             discrete=F,
                             option = "turbo",
                             direction = -1,
                             na.value = "white") +
ylab("Location") +
xlab("Weekly Timesteps (2010-2023)") +
facet_wrap(~set, ncol = 4) +
theme(panel.grid.minor = element_blank(),
      panel.grid.major = element_blank(),
      panel.background = element_blank(),
      plot.background = element_blank(),
      panel.border = element_blank(),
      legend.title = element_text(size = 16, face = "bold", hjust=0.5),
      legend.text = element_text(size=10, face="bold"),
      strip.text = element_text(size=16, face="bold"),
      strip.background = element_blank(),
      legend.position="none", 
      legend.direction = "horizontal",
      legend.box = "horizontal",
      axis.text.y = element_text(face="bold", size=5),
      axis.text.x = element_text(face="bold", size=12, vjust=0.5,
                                 hjust=1, angle=90),
      axis.title.x = element_text(size=12, face="bold"),
      axis.title.y = element_text(size=18, face="bold"),
      plot.title = element_text(size=18, face="bold", hjust=0.5)) +
guides(color = guide_legend(title.position = "top", label.position = "bottom"))
```

```{r warning=FALSE, message=FALSE,echo=FALSE}
#save(list=c("nrevss_full", "J", "ilinet_full", "flu_HHS_full"), file="./data/prepro_06072023.RData", version = 2)
```
