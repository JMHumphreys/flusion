{
  "hash": "9d25271449b6b2e870ad6b2cf84a425b",
  "result": {
    "markdown": "---\ntitle: \"Preprocessing\"\ndescription: \"Import and wrangle mutlisourced influenza observations\"\nformat:\n  html:\n    df-print: kable\n    code-fold: show\n    code-summary: \"Hide code\"\n    code-overflow: wrap\n    toc-title: Page Contents\n    toc: true\n    toc-depth: 2\n    toc-location: right\n    number-sections: false\n    html-math-method: katex\n    css: styles.css\n    theme: flatly\n    smooth-scroll: true\neditor_options: \n  chunk_output_type: console\n---\n\n```{=html}\n<style type=\"text/css\">\n\nbody, td {\n   font-size: 13pt;\n}\ncode.r{\n  font-size: 9pt;\n}\npre {\n  font-size: 11pt\n}\n</style>\n```\n\n# Preliminaries\n \nSetup working environment and loading necessary packages.\n\n## Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#wrangling\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(data.table, include.only = \"fread\")\nlibrary(cdcfluview)\nlibrary(yaml)\n\n#spatial\nlibrary(sp)\nlibrary(sf)\nlibrary(spdep)\nlibrary(rgeos)\nlibrary(igraph)\nlibrary(maptools)\nlibrary(mapproj)\nlibrary(CovidCAR)\n#devtools::install_github(\"JMHumphreys/CovidCAR\")\n\n#messages\nlibrary(cli)\n\n#inference\nlibrary(INLA)\n\n#Utilities\n#source(\"./R/utilities.R\")\n\noptions(dplyr.summarise.inform = FALSE)\n\n#function\ndownload_file <- function(url, filename) {\n  download.file(url, destfile = filename, method = \"auto\", quiet = FALSE, mode = \"wb\")\n}\n```\n:::\n\n\n# Observation Data\n\n## FluSurv\n\nBuild a flu hospitalization data file from individual state reports and all available years. The *hospitalizations()* function from the **cdcfluview** package does most of the work by querying [FluView](https://gis.cdc.gov/GRASP/Fluview/FluHospRates.html), but seems only to be able to take small bites at a time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyRegions <- surveillance_areas() \n\nflusurv_all <- do.call(rbind, lapply(seq_len(dim(myRegions)[1]), function(i) {\n  hospitalizations(surveillance_area = myRegions$surveillance_area[i], region = myRegions$region[i])\n}))\n```\n:::\n\n\nWrangle Flusurv data:\\\nNote that the **cdcfluview** package only includes through Spring of 2020. Because of this, the data is filtered at 2019 and a static file manually downloaded from FluView with more recnt reports (eventually this data will be moved to www.healthdata.gov).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrange(flusurv_all$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2003 2020\n```\n:::\n\n```{.r .cell-code}\nflusurv <- flusurv_all %>%\n  filter(age_label == \"Overall\",\n         region != \"Entire Network\",\n         year >= 2010 & year <= 2019) %>% #the pkg fails on dates after 2020,ugh\n  mutate(location_name = region,\n         network = surveillance_area,\n         weeklyrate = as.numeric(weeklyrate),\n         epiweek = year_wk_num) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n  \n#manual download from site 2023-06-01\nflusurv_2020 <- fread(\"D:/Github/flusion/data/FluSurveillance_2020.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  filter(AGECATEGORY == \"Overall\",\n         SEXCATEGORY == \"Overall\",\n         RACECATEGORY == \"Overall\",\n         CATCHMENT != \"Entire Network\",\n         MMWRYEAR >= 2020) %>% #Prior to this date was downloaded in code above\n  mutate(location_name = CATCHMENT,\n         network = NETWORK,\n         year = MMWRYEAR,\n         epiweek = MMWRWEEK,\n         rate = CUMULATIVERATE,\n         weeklyrate = as.numeric(WEEKLYRATE)) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n\n#Join date ranges and scale weeklyrate\nflusurv = rbind(flusurv, flusurv_2020)\nflusurv$weeklyrate.s = as.numeric(scale(flusurv$weeklyrate, scale = T, center=T))\n\n#combine NY data\nflusurv$location_name[flusurv$location_name == \"New York - Albany\"] = \"New York\"\nflusurv$location_name[flusurv$location_name == \"New York - Rochester\"] =\"New York\"\n\nflusurv <- flusurv %>%\n  group_by(location_name, year, epiweek) %>%\n  summarise(rate = mean(rate, na.rm=T),\n            weeklyrate = mean(weeklyrate, na.rm=T),\n            weeklyrate.s = mean(weeklyrate.s, na.rm=T))\n\n\n#Check for duplicates\nunique(duplicated(flusurv))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\ndim(flusurv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5676    6\n```\n:::\n\n```{.r .cell-code}\nhead(flusurv)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|location_name | year| epiweek| rate| weeklyrate| weeklyrate.s|\n|:-------------|----:|-------:|----:|----------:|------------:|\n|California    | 2010|       1|   NA|        0.4|   -0.4771582|\n|California    | 2010|       2|   NA|        0.2|   -0.5561987|\n|California    | 2010|       3|   NA|        0.2|   -0.5561987|\n|California    | 2010|       4|   NA|        0.2|   -0.5561987|\n|California    | 2010|       5|   NA|        0.2|   -0.5561987|\n|California    | 2010|       6|   NA|        0.1|   -0.5957189|\n\n</div>\n:::\n:::\n\n\nSame FluSurv process as above, but now for the Full Network reports\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflusurv_en <- flusurv_all %>%\n  filter(age_label == \"Overall\",\n         region == \"Entire Network\",\n         year >= 2010 & year <= 2019) %>% #the pkg fails on dates after 2020,ugh\n  mutate(location_name = region,\n         network = surveillance_area,\n         epiweek = year_wk_num) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n\nflusurv_en2020 <- fread(\"D:/Github/flusion/data/FluSurveillance_2020.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  filter(AGECATEGORY == \"Overall\",\n         SEXCATEGORY == \"Overall\",\n         RACECATEGORY == \"Overall\",\n         CATCHMENT == \"Entire Network\",\n         MMWRYEAR >= 2020) %>% #the pkg fails on dates after 2020,ugh\n  mutate(location_name = CATCHMENT,\n         network = NETWORK,\n         year = MMWRYEAR,\n         epiweek = MMWRWEEK,\n         rate = CUMULATIVERATE,\n         weeklyrate = WEEKLYRATE) %>%\n    select(location_name, year, epiweek, network, rate, weeklyrate)\n\n#Join\nflusurv_en <- rbind(flusurv_en, flusurv_en2020)\nunique(duplicated(flusurv_en))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\ndim(flusurv_en)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1131    6\n```\n:::\n\n```{.r .cell-code}\nhead(flusurv_en)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|location_name  | year| epiweek|network     |rate |weeklyrate |\n|:--------------|----:|-------:|:-----------|:----|:----------|\n|Entire Network | 2016|      40|FluSurv-NET |0.1  |0.1        |\n|Entire Network | 2016|      41|FluSurv-NET |0.2  |0.1        |\n|Entire Network | 2016|      42|FluSurv-NET |0.3  |0.1        |\n|Entire Network | 2016|      43|FluSurv-NET |0.4  |0.1        |\n|Entire Network | 2016|      44|FluSurv-NET |0.6  |0.1        |\n|Entire Network | 2016|      45|FluSurv-NET |0.8  |0.2        |\n\n</div>\n:::\n:::\n\n\n## ILINet Surveillance Data\n\nInfluenza Like Illness (ILI) data using **cdcfluview** package. Unlike FluSurv, data is available 2010-2013.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nilinet <- ilinet(region = \"state\") %>%\n  mutate(location_name = region,\n         epiweek = week,\n         unweighted = as.numeric(unweighted_ili),\n         unweighted.s = unweighted,\n         total = ilitotal,\n         providers = num_of_providers) %>%\n  select(location_name, year, epiweek, unweighted, unweighted.s, total, providers)\n\n# Clip to between 0.0001 and 99.999\nilinet$unweighted.s <- pmin(pmax(as.numeric(ilinet$unweighted.s), 0.01), 99.99)/100\n\n# logit transform \nilinet$unweighted.s <- log(ilinet$unweighted.s/(1-ilinet$unweighted.s))\nrange(ilinet$unweighted.s, na.rm=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -9.210240 -1.423094\n```\n:::\n\n```{.r .cell-code}\nunique(duplicated(ilinet))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\ndim(ilinet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 35678     7\n```\n:::\n\n```{.r .cell-code}\nrange(ilinet$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2010 2023\n```\n:::\n\n```{.r .cell-code}\nhead(ilinet)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|location_name | year| epiweek| unweighted| unweighted.s| total| providers|\n|:-------------|----:|-------:|----------:|------------:|-----:|---------:|\n|Alabama       | 2010|      40|   2.134770|    -3.825232|   249|        35|\n|Alaska        | 2010|      40|   0.875146|    -4.729745|    15|         7|\n|Arizona       | 2010|      40|   0.674721|    -4.991856|   172|        49|\n|Arkansas      | 2010|      40|   0.696056|    -4.960510|    18|        15|\n|California    | 2010|      40|   1.954120|    -3.915496|   632|       112|\n|Colorado      | 2010|      40|   0.660684|    -5.013021|   134|        14|\n\n</div>\n:::\n:::\n\n\n## COVID19 RPIHC\n\nDownloading the COVID-19 Reported Patient Impact and Hospital Capacity by State Timeseries from https://healthdata.gov/.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD\"\nfilename <- \"D:/Github/flusion/data/flu_HHS.csv\"\n\ndownload_file(url, filename)\n```\n:::\n\n\nRead and wrangle RPIHC:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflu_HHS <- fread(\"D:/Github/flusion/data/flu_HHS.csv\") %>%\n  mutate(abbreviation = state,\n         date = as_date(date) - 1, #1-day prior, per fluSight truth\n         year = year(date),\n         epiweek = epiweek(date)) %>%\n  group_by(abbreviation, year, epiweek) %>%\n  summarise(hosp_inc = sum(previous_day_admission_influenza_confirmed))\n\nunique(duplicated(flu_HHS))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\ndim(flu_HHS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9346    4\n```\n:::\n\n```{.r .cell-code}\nrange(flu_HHS$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2019 2023\n```\n:::\n\n```{.r .cell-code}\nhead(flu_HHS)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation | year| epiweek| hosp_inc|\n|:------------|----:|-------:|--------:|\n|AK           | 2020|      13|       NA|\n|AK           | 2020|      14|       NA|\n|AK           | 2020|      15|       NA|\n|AK           | 2020|      16|       NA|\n|AK           | 2020|      17|       NA|\n|AK           | 2020|      18|       NA|\n\n</div>\n:::\n:::\n\n\n## NREVSS\n\nNational Respiratory and Enteric Virus Surveillance System.\n\nAgain, unfortunately only available through a manual: https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html\\\nFiles illustrated here were downloaded on June 2, 2023.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnrevss.1 <- fread(\"D:/Github/flusion/data/WHO_NREVSS_Combined_prior_to_2015_16.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  mutate(location_name = REGION,\n         year = YEAR,\n         epiweek = WEEK,\n         tot_perc = as.numeric(PERCENTPOSITIVE),\n         Bpos = as.numeric(B),\n         tot_samp = as.numeric(TOTALSPECIMENS),\n         Apos = tot_perc - ((Bpos/tot_samp)*100)) %>%\n  select(location_name, year, epiweek, Apos)\n\n\nnrevss.2 <- fread(\"D:/Github/flusion/data/WHO_NREVSS_Clinical_Labs.csv\") %>%\n  rename_all(~gsub(\" |-\", \"\", .)) %>%\n  mutate(location_name = REGION,\n         year = YEAR,\n         epiweek = WEEK,\n         Apos = PERCENTA) %>%\n  select(location_name, year, epiweek, Apos) #Apos = Influenza A positive\n\n# Combine \nnrevss <- rbind(nrevss.1, nrevss.2)\n\n# Replace \"X\" \nnrevss$Apos[nrevss$Apos == \"X\"] <- NA\n\n# Clip to between 0.0001 and 99.999\nnrevss$Apos <- pmin(pmax(as.numeric(nrevss$Apos), 0.01), 99.99)/100\n\n# logit transform \nnrevss$Apos.s <- log(nrevss$Apos/(1-nrevss$Apos))\nunique(duplicated(nrevss))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nhead(nrevss)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|location_name | year| epiweek|      Apos|    Apos.s|\n|:-------------|----:|-------:|---------:|---------:|\n|Alabama       | 2010|      40| 0.0001000| -9.210240|\n|Alaska        | 2010|      40| 0.0001000| -9.210240|\n|Arizona       | 2010|      40| 0.0250000| -3.663562|\n|Arkansas      | 2010|      40| 0.0001000| -9.210240|\n|California    | 2010|      40| 0.0273355| -3.571852|\n|Colorado      | 2010|      40| 0.0079000| -4.832961|\n\n</div>\n:::\n:::\n\n\n# Location Template\n\n## Location Table\n\nLocation codes and population numbers from FluSight. Should really get varying census over time period, but these are a start.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://github.com/cdcepi/Flusight-forecast-data/raw/master/data-locations/locations.csv\"\nfilename <- \"D:/Github/flusion/data/locations.csv\"\n\ndownload_file(url, filename)\n```\n:::\n\n\nRead locations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlocations <- fread(\"D:/Github/flusion/data/locations.csv\") %>%\n  select(-c(count_rate1per100k, count_rate2per100k)) %>%\n  filter(location_name != \"US\") #remove aggregate group\n\nhead(locations)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation |location |location_name | population|\n|:------------|:--------|:-------------|----------:|\n|AL           |01       |Alabama       |    5039877|\n|AK           |02       |Alaska        |     732673|\n|AZ           |04       |Arizona       |    7276316|\n|AR           |05       |Arkansas      |    3025891|\n|CA           |06       |California    |   39237836|\n|CO           |08       |Colorado      |    5812069|\n\n</div>\n:::\n:::\n\n\n# Template\n\nEnsure all locations and times are represented in the analysis. Missing data are plugged with NA.\n\n## Dates and Locations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyYears <- seq(2010, 2023, by = 1)\nweek_nums <- 1:52\n\nyear_set <- lapply(myYears, function(year) {\n  tmp_frame <- locations %>% mutate(year = year)\n  \n  weekly_set <- lapply(week_nums, function(week_num) {\n    tmp_frame_wk <- tmp_frame %>% mutate(epiweek = week_num)\n    return(tmp_frame_wk)\n  })\n  \n  weekly_set <- do.call(rbind, weekly_set)\n  return(weekly_set)\n})\n\ntemplate <- do.call(rbind, year_set)\n\ndim(template)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38584     6\n```\n:::\n\n```{.r .cell-code}\nhead(template) #all states and times represented\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation |location |location_name | population| year| epiweek|\n|:------------|:--------|:-------------|----------:|----:|-------:|\n|AL           |01       |Alabama       |    5039877| 2010|       1|\n|AK           |02       |Alaska        |     732673| 2010|       1|\n|AZ           |04       |Arizona       |    7276316| 2010|       1|\n|AR           |05       |Arkansas      |    3025891| 2010|       1|\n|CA           |06       |California    |   39237836| 2010|       1|\n|CO           |08       |Colorado      |    5812069| 2010|       1|\n\n</div>\n:::\n\n```{.r .cell-code}\nfirst_record <- min(subset(nrevss, year == 2010)$epiweek) #drop before nrevss data was collected\ntemplate$drop_old <- ifelse(template$year == 2010 & template$epiweek < first_record, \"drop\", \"keep\")\n\n#most_recent <- max(subset(flu_HHS, year == 2023)$epiweek) #drop future dates\nmost_recent <- 22 #date available when model run\ntemplate$drop_new <- ifelse(template$year == 2023 & template$epiweek > most_recent, \"drop\", \"keep\")\n\ntemplate <- template %>% \n  filter(drop_old == \"keep\" &\n         drop_new == \"keep\") %>%\n  select(-c(drop_old, drop_new))\n\nunique(duplicated(template))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\n## Time Steps\n\nAn index with sequential timesteps.\n\n::: {.cell}\n\n```{.r .cell-code}\ntemplate <- template %>%\n  arrange(year, epiweek) %>%\n  mutate(ts_week = as.integer(as.factor(year + (epiweek/53))))\n\n\nrange(template$ts_week) #number of epiweeks\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]   1 659\n```\n:::\n:::\n\n\n# Spatial Domian\n\nNeed to setup directories to use **CovidCAR** functions. Values here are arbitrary (need to add option to bypass to CovidCAR)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetup_analysis(report_date = \"2010-01-01\", \n               training_period = 2*28, #days\n               forecast_horizon = 28, #days\n               output_dir = \"D:/Github/flusion/data\"\n)\n```\n:::\n\n\n## Get Geographic Boundaries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStates <- download_boundaries(unit = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `us-state-boundaries' from data source \n  `D:\\Github\\flusion\\data\\2010-01-01-CovidCAR-run2023-06-14\\polygons' \n  using driver `ESRI Shapefile'\nSimple feature collection with 56 features and 20 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.44069\nGeodetic CRS:  WGS 84\n```\n:::\n\n```{.r .cell-code}\nclass(States)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n```\n:::\n\n```{.r .cell-code}\nhead(States@data[,c(\"Region\", \"State\")]) #appended attributes  \n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Region|State          |\n|------:|:--------------|\n|      1|Virgin Islands |\n|      2|Wisconsin      |\n|      3|Vermont        |\n|      4|New Jersey     |\n|      5|Colorado       |\n|      6|South Carolina |\n\n</div>\n:::\n:::\n\n\n## Adjacency\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_flusion = get_neighbors(States, connect=TRUE)\nsummary(nb_flusion)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNeighbour list object:\nNumber of regions: 56 \nNumber of nonzero links: 242 \nPercentage nonzero weights: 7.716837 \nAverage number of links: 4.321429 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8 \n 5  3 10 12 10 11  3  2 \n5 least connected regions:\n1 13 38 42 54 with 1 link\n2 most connected regions:\n49 56 with 8 links\n```\n:::\n\n```{.r .cell-code}\n#view\nplot_neighbors(States, nb_flusion)\n```\n\n::: {.cell-output-display}\n![](preprocessing_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n\n```{.r .cell-code}\n#convert to matrix\nnb2INLA(\"J\", nb_flusion)\nJ = inla.read.graph(\"J\")\n```\n:::\n\n\n## Template Spatial Index\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemplate$Region =  with(States@data[,c(\"Region\", \"State\")],\n                       Region[match(\n                        template$location_name,\n                                 State)])\n```\n:::\n\n\n## Add Entire Network\n\nGetting the flue weeklyrate from FluSurv. Not that this is only the time trend from FluSurv and is not loaction specific.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nen_match <- flusurv_en %>%\n  group_by(year, epiweek) %>%\n  summarise(en_est = mean(as.numeric(weeklyrate), na.rm=TRUE)) %>%\n  select(year, epiweek, en_est)\n\n# Clip to between 0.0001 and 99.999\nen_match$en_est.s <- pmin(pmax(as.numeric(en_match$en_est), 0.01), 99.99)/100\n\n# logit transform \nen_match$en_est.s <- round(log(en_match$en_est.s/(1-en_match$en_est.s)), 3)\nrange(en_match$en_est.s, na.rm=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -9.21 -2.19\n```\n:::\n\n```{.r .cell-code}\ntemplate <- left_join(template, en_match, by = c(\"year\", \"epiweek\"))\nunique(duplicated(template))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\n## Space-Time Interaction Index\n\nAll location-time combinations.  \n\n::: {.cell}\n\n```{.r .cell-code}\ntemplate$st_int <- as.integer(as.factor(paste0(template$Region, \".\", template$ts_week)))\nrange(template$st_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]     1 34927\n```\n:::\n:::\n\n\n# Join to Disease Data\n\nJoin observation data to the template. Times and locations without observations are coded as NA.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#FluSurv\nflusurv_full <- left_join(template, flusurv, by = c(\"location_name\", \"year\", \"epiweek\")) \nflusurv_full$network[is.na(flusurv_full$network)] = \"none\"\nunique(duplicated(flusurv_full))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nhead(flusurv_full) #times and locations w/out values assigned NA\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation |location |location_name | population| year| epiweek| ts_week| Region|    en_est| en_est.s| st_int| rate| weeklyrate| weeklyrate.s|network |\n|:------------|:--------|:-------------|----------:|----:|-------:|-------:|------:|---------:|--------:|------:|----:|----------:|------------:|:-------|\n|AL           |01       |Alabama       |    5039877| 2010|      40|       1|     21| 0.0333333|   -8.006|   8568|   NA|         NA|           NA|NA      |\n|AK           |02       |Alaska        |     732673| 2010|      40|       1|     38| 0.0333333|   -8.006|  19771|   NA|         NA|           NA|NA      |\n|AZ           |04       |Arizona       |    7276316| 2010|      40|       1|     11| 0.0333333|   -8.006|   1319|   NA|         NA|           NA|NA      |\n|AR           |05       |Arkansas      |    3025891| 2010|      40|       1|     34| 0.0333333|   -8.006|  17135|   NA|         NA|           NA|NA      |\n|CA           |06       |California    |   39237836| 2010|      40|       1|     47| 0.0333333|   -8.006|  25702|   NA|        0.1|   -0.5957189|NA      |\n|CO           |08       |Colorado      |    5812069| 2010|      40|       1|      5| 0.0333333|   -8.006|  27679|   NA|        0.1|   -0.5957189|NA      |\n\n</div>\n:::\n\n```{.r .cell-code}\n#ILI Surveillance\nilinet_full <- left_join(template, ilinet, by = c(\"location_name\", \"year\", \"epiweek\"))\nunique(duplicated(ilinet_full))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nhead(ilinet_full)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation |location |location_name | population| year| epiweek| ts_week| Region|    en_est| en_est.s| st_int| unweighted| unweighted.s| total| providers|\n|:------------|:--------|:-------------|----------:|----:|-------:|-------:|------:|---------:|--------:|------:|----------:|------------:|-----:|---------:|\n|AL           |01       |Alabama       |    5039877| 2010|      40|       1|     21| 0.0333333|   -8.006|   8568|   2.134770|    -3.825232|   249|        35|\n|AK           |02       |Alaska        |     732673| 2010|      40|       1|     38| 0.0333333|   -8.006|  19771|   0.875146|    -4.729745|    15|         7|\n|AZ           |04       |Arizona       |    7276316| 2010|      40|       1|     11| 0.0333333|   -8.006|   1319|   0.674721|    -4.991856|   172|        49|\n|AR           |05       |Arkansas      |    3025891| 2010|      40|       1|     34| 0.0333333|   -8.006|  17135|   0.696056|    -4.960510|    18|        15|\n|CA           |06       |California    |   39237836| 2010|      40|       1|     47| 0.0333333|   -8.006|  25702|   1.954120|    -3.915496|   632|       112|\n|CO           |08       |Colorado      |    5812069| 2010|      40|       1|      5| 0.0333333|   -8.006|  27679|   0.660684|    -5.013021|   134|        14|\n\n</div>\n:::\n\n```{.r .cell-code}\n#HHS \nflu_HHS_full <- left_join(template, flu_HHS, by = c(\"abbreviation\", \"year\", \"epiweek\"))\nunique(duplicated(flu_HHS_full))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nunique(duplicated(flu_HHS_full[,c(\"ts_week\", \"Region\")]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nhead(flu_HHS_full)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation |location |location_name | population| year| epiweek| ts_week| Region|    en_est| en_est.s| st_int| hosp_inc|\n|:------------|:--------|:-------------|----------:|----:|-------:|-------:|------:|---------:|--------:|------:|--------:|\n|AL           |01       |Alabama       |    5039877| 2010|      40|       1|     21| 0.0333333|   -8.006|   8568|       NA|\n|AK           |02       |Alaska        |     732673| 2010|      40|       1|     38| 0.0333333|   -8.006|  19771|       NA|\n|AZ           |04       |Arizona       |    7276316| 2010|      40|       1|     11| 0.0333333|   -8.006|   1319|       NA|\n|AR           |05       |Arkansas      |    3025891| 2010|      40|       1|     34| 0.0333333|   -8.006|  17135|       NA|\n|CA           |06       |California    |   39237836| 2010|      40|       1|     47| 0.0333333|   -8.006|  25702|       NA|\n|CO           |08       |Colorado      |    5812069| 2010|      40|       1|      5| 0.0333333|   -8.006|  27679|       NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n#nrevss \nnrevss_full <- left_join(template, nrevss, by = c(\"location_name\", \"year\", \"epiweek\"))\nunique(duplicated(nrevss_full))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nhead(nrevss_full)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|abbreviation |location |location_name | population| year| epiweek| ts_week| Region|    en_est| en_est.s| st_int|      Apos|    Apos.s|\n|:------------|:--------|:-------------|----------:|----:|-------:|-------:|------:|---------:|--------:|------:|---------:|---------:|\n|AL           |01       |Alabama       |    5039877| 2010|      40|       1|     21| 0.0333333|   -8.006|   8568| 0.0001000| -9.210240|\n|AK           |02       |Alaska        |     732673| 2010|      40|       1|     38| 0.0333333|   -8.006|  19771| 0.0001000| -9.210240|\n|AZ           |04       |Arizona       |    7276316| 2010|      40|       1|     11| 0.0333333|   -8.006|   1319| 0.0250000| -3.663562|\n|AR           |05       |Arkansas      |    3025891| 2010|      40|       1|     34| 0.0333333|   -8.006|  17135| 0.0001000| -9.210240|\n|CA           |06       |California    |   39237836| 2010|      40|       1|     47| 0.0333333|   -8.006|  25702| 0.0273355| -3.571852|\n|CO           |08       |Colorado      |    5812069| 2010|      40|       1|      5| 0.0333333|   -8.006|  27679| 0.0079000| -4.832961|\n\n</div>\n:::\n:::\n\n\n## View Coverage\n\nLooking at holes in the data. Not interested in exact values, only comparing data coverage.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfs_plt <- flusurv_full %>% \n  mutate(value = weeklyrate.s,\n         set = \"FluSurv\") %>%\n  select(location_name, ts_week, value, set)\n\nili_plt <- ilinet_full %>% \n  mutate(value = unweighted.s,\n          set = \"ILI\") %>%\n  select(location_name, ts_week, value, set)\n\nhhs_plt <- flu_HHS_full %>% \n  mutate(value = log(hosp_inc+0.0001),\n          set = \"HHS\") %>%\n  select(location_name, ts_week, value, set)\n\nnrevss_plt <- nrevss_full %>% \n  mutate(value = Apos.s,\n          set = \"NREVSS\") %>%\n  select(location_name, ts_week, value, set)\n\n\nall_plts <- rbind(fs_plt, ili_plt, hhs_plt, nrevss_plt)\nall_plts$set <- ordered(factor(all_plts$set), levels = c(\"FluSurv\", \"ILI\", \"NREVSS\", \"HHS\"))\n\nggplot() +\ngeom_tile(data=all_plts,\n          aes(ts_week, location_name, fill = value)) +\nxlab(\" \") +\nviridis::scale_fill_viridis(paste0(\" \"),\n                             discrete=F,\n                             option = \"turbo\",\n                             direction = -1,\n                             na.value = \"white\") +\nylab(\"Location\") +\nxlab(\"Weekly Timesteps (2010-2023)\") +\nfacet_wrap(~set, ncol = 4) +\ntheme(panel.grid.minor = element_blank(),\n      panel.grid.major = element_blank(),\n      panel.background = element_blank(),\n      plot.background = element_blank(),\n      panel.border = element_blank(),\n      legend.title = element_text(size = 16, face = \"bold\", hjust=0.5),\n      legend.text = element_text(size=10, face=\"bold\"),\n      strip.text = element_text(size=16, face=\"bold\"),\n      strip.background = element_blank(),\n      legend.position=\"none\", \n      legend.direction = \"horizontal\",\n      legend.box = \"horizontal\",\n      axis.text.y = element_text(face=\"bold\", size=5),\n      axis.text.x = element_text(face=\"bold\", size=12, vjust=0.5,\n                                 hjust=1, angle=90),\n      axis.title.x = element_text(size=12, face=\"bold\"),\n      axis.title.y = element_text(size=18, face=\"bold\"),\n      plot.title = element_text(size=18, face=\"bold\", hjust=0.5)) +\nguides(color = guide_legend(title.position = \"top\", label.position = \"bottom\"))\n```\n\n::: {.cell-output-display}\n![](preprocessing_files/figure-html/unnamed-chunk-20-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "preprocessing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}